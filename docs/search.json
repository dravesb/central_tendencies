[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "My name is Benjamin Draves and I’m a Senior Applied Scientist at Uber in NYC. I work on building ML recommendation and targeting systems to grow Uber’s consumer and earner businesses.\nBefore Uber, I received my Ph.D. in Statistics from Boston University and wrote my dissertation on spectral embedding methods for multiple network data and continue to study network science and matrix analysis methods. Outside of work, I enjoy distance running, soccer, reading, and exploring NYC."
  },
  {
    "objectID": "about.html#data-science-topics-that-excite-me",
    "href": "about.html#data-science-topics-that-excite-me",
    "title": "About Me",
    "section": "Data Science Topics that Excite Me",
    "text": "Data Science Topics that Excite Me\n\nRecommendation Systems\nCausal Machine Learning\nGraph Embeddings and Network Inference\nStatistical Pedagogy"
  },
  {
    "objectID": "about.html#experiences-education",
    "href": "about.html#experiences-education",
    "title": "About Me",
    "section": "Experiences & Education",
    "text": "Experiences & Education\n\n[2022-Present] Applied Scientist @ Uber\n[2017-2022] Ph.D. | M.A. in Stat @ Boston University\n[2014-2017] B.S. in Math @ Lafayette College"
  },
  {
    "objectID": "about.html#contact-information",
    "href": "about.html#contact-information",
    "title": "About Me",
    "section": "Contact Information",
    "text": "Contact Information\nIf you wish to discuss what I’m working on please feel free to email me at benjamin.draves@gmail.com."
  },
  {
    "objectID": "blog/working_on/working_on_scroll.html",
    "href": "blog/working_on/working_on_scroll.html",
    "title": "Working On",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "blog/reading/reading_scroll.html",
    "href": "blog/reading/reading_scroll.html",
    "title": "Reading",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nNov 11, 2024\n\n\nML with PyTorch & Scikit-Learn: Chapter 11\n\n\nBenjamin Draves\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to Central Tendencies",
    "section": "",
    "text": "Welcome to my blog - Central Tendencies. My name is Benjamin Draves and I’m a Senior Applied Scientist at Uber in NYC. I’m interested in recommendation systems, causal machine learning, and statistics and tend to write about these topics. The purpose of Central Tendencies is to share what I am reading about and working on in hope of starting conversations with fellow data scientists and statisticians. If you wish to discuss what I’m working on, please feel free to reach out at benjamin.draves@gmail.com."
  },
  {
    "objectID": "blog/thinking_about/thinking_about_scroll.html",
    "href": "blog/thinking_about/thinking_about_scroll.html",
    "title": "Thinking About",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "blog/blog.html",
    "href": "blog/blog.html",
    "title": "Welcome to Central Tendencies",
    "section": "",
    "text": "I’m writting about two topics:\n\nI am reading a series of classical papers in recommendation systems in preparation for a new member joining. I’ll be going through the traditional papers on collaborative filtering, matrix factorization, learn-to-rank, and Neural\nI’m currently working my way through Machine Learning with PyTorch and Scikit-Learn by Raschka, Lui, and Mirjalili to become more comfortable with PyTorch for multi-output models and GNNs for recommender applications. You can find my notes below.\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJan 1, 2000\n\n\nTemplate\n\n\nBenjamin Draves\n\n\n\n\nNov 11, 2024\n\n\nML with PyTorch & Scikit-Learn: Chapter 11\n\n\nBenjamin Draves\n\n\n\n\nNov 17, 2024\n\n\nPaper Notes - GroupLens: An Open Architecture for Collaborative Filtering of Netnews\n\n\nBenjamin Draves\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/blog.html#what-i-am-currently",
    "href": "blog/blog.html#what-i-am-currently",
    "title": "Welcome to Central Tendencies",
    "section": "What I am currently…",
    "text": "What I am currently…\n\nReading\nI’m currently working my way through Machine Learning with PyTorch and Scikit-Learn by Raschka, Lui, and Mirjalili to become more comfortable with (i) PyTorch for multi-output models and (ii) GNNs for recommender applications. You can find my notes here.\n\n\n\n\n\n\n\nWorking On"
  },
  {
    "objectID": "blog/blog.html#what-i-was",
    "href": "blog/blog.html#what-i-was",
    "title": "Welcome to Central Tendencies",
    "section": "What I was …",
    "text": "What I was …\n\nReading\n\n\nWorking on"
  },
  {
    "objectID": "blog/reading/reading_posts/ml_with_pytorch_chp11/index.html",
    "href": "blog/reading/reading_posts/ml_with_pytorch_chp11/index.html",
    "title": "ML with PyTorch & Scikit-Learn: Chapter 11",
    "section": "",
    "text": "\\[\n\\mathbb{E}[x] = \\int_{0}^{\\infty} xf(x)dx\n\\]"
  },
  {
    "objectID": "blog/blog.html#what-i-am-currently-working-on",
    "href": "blog/blog.html#what-i-am-currently-working-on",
    "title": "Welcome to Central Tendencies",
    "section": "What I am currently working on…",
    "text": "What I am currently working on…\nI’m currently working my way through Machine Learning with PyTorch and Scikit-Learn by Raschka, Lui, and Mirjalili to become more comfortable with (i) PyTorch for multi-output models and (ii) GNNs for recommender applications. You can find my notes here."
  },
  {
    "objectID": "blog/blog.html#what-i-was-working-on",
    "href": "blog/blog.html#what-i-was-working-on",
    "title": "Welcome to Central Tendencies",
    "section": "What I was working on…",
    "text": "What I was working on…\nYou can find what I was working on here."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Welcome to Central Tendencies",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nNov 11, 2024\n\n\nML with PyTorch & Scikit-Learn: Chapter 11\n\n\nBenjamin Draves\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about copy.html",
    "href": "about copy.html",
    "title": "About Me",
    "section": "",
    "text": "My name is Benjamin Draves and I’m a Senior Applied Scientist at Uber in NYC. I work on building ML recommendation and targeting systems to grow Uber’s consumer and earner businesses.\nBefore Uber, I received my Ph.D. in Statistics from Boston University and wrote my dissertation on spectral embedding methods for multiple network data and continue to study network science and matrix analysis methods. Outside of work, I enjoy distance running, soccer, reading, and exploring NYC."
  },
  {
    "objectID": "about copy.html#data-science-topics-that-excite-me",
    "href": "about copy.html#data-science-topics-that-excite-me",
    "title": "About Me",
    "section": "Data Science Topics that Excite Me",
    "text": "Data Science Topics that Excite Me\n\nRecommendation Systems\nCausal Machine Learning\nGraph Embeddings and Network Inference\nStatistical Pedagogy"
  },
  {
    "objectID": "about copy.html#experiences-education",
    "href": "about copy.html#experiences-education",
    "title": "About Me",
    "section": "Experiences & Education",
    "text": "Experiences & Education\n\n[2022-Present] Applied Scientist @ Uber\n[2017-2022] Ph.D. | M.A. in Stat @ Boston University\n[2014-2017] B.S. in Math @ Lafayette College"
  },
  {
    "objectID": "about copy.html#contact-information",
    "href": "about copy.html#contact-information",
    "title": "About Me",
    "section": "Contact Information",
    "text": "Contact Information\nIf you wish to discuss what I’m working on please feel free to email me at benjamin.draves@gmail.com."
  },
  {
    "objectID": "blog_posts/ml_with_pytorch_chp11/index.html",
    "href": "blog_posts/ml_with_pytorch_chp11/index.html",
    "title": "ML with PyTorch & Scikit-Learn: Chapter 11",
    "section": "",
    "text": "For a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: A line plot on a polar axis\n\n\n\n\n\n\\[\n\\mathbb{E}[x] = \\int_{0}^{\\infty} xf(x)dx\n\\]"
  },
  {
    "objectID": "code/resnick_1994/resnick_1994_demo.html",
    "href": "code/resnick_1994/resnick_1994_demo.html",
    "title": "User Collaborative Filtering",
    "section": "",
    "text": "This script accommodates implementation of user-collaborative filtering from the original GroupLens paper (Resnick et al 1994). See here for a full write up"
  },
  {
    "objectID": "code/resnick_1994/resnick_1994_demo.html#working-with-scipy.sparse",
    "href": "code/resnick_1994/resnick_1994_demo.html#working-with-scipy.sparse",
    "title": "User Collaborative Filtering",
    "section": "Working with scipy.sparse",
    "text": "Working with scipy.sparse\n\nprint(dir(ratings[0]))\n\n['__abs__', '__add__', '__array_priority__', '__bool__', '__class__', '__delattr__', '__dict__', '__dir__', '__div__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__idiv__', '__imul__', '__init__', '__init_subclass__', '__isub__', '__iter__', '__itruediv__', '__le__', '__len__', '__lt__', '__matmul__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__pow__', '__radd__', '__rdiv__', '__reduce__', '__reduce_ex__', '__repr__', '__rmatmul__', '__rmul__', '__round__', '__rsub__', '__rtruediv__', '__setattr__', '__setitem__', '__sizeof__', '__slotnames__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__weakref__', '_add_dense', '_add_sparse', '_arg_min_or_max', '_arg_min_or_max_axis', '_asindices', '_binopt', '_cs_matrix__get_has_canonical_format', '_cs_matrix__get_sorted', '_cs_matrix__set_has_canonical_format', '_cs_matrix__set_sorted', '_deduped_data', '_divide', '_divide_sparse', '_get_arrayXarray', '_get_arrayXint', '_get_arrayXslice', '_get_columnXarray', '_get_dtype', '_get_intXarray', '_get_intXint', '_get_intXslice', '_get_sliceXarray', '_get_sliceXint', '_get_sliceXslice', '_get_submatrix', '_imag', '_inequality', '_insert_many', '_major_index_fancy', '_major_slice', '_maximum_minimum', '_min_or_max', '_min_or_max_axis', '_minor_index_fancy', '_minor_reduce', '_minor_slice', '_mul_multivector', '_mul_scalar', '_mul_sparse_matrix', '_mul_vector', '_prepare_indices', '_process_toarray_args', '_real', '_rsub_dense', '_scalar_binopt', '_set_arrayXarray', '_set_arrayXarray_sparse', '_set_dtype', '_set_intXint', '_set_many', '_set_self', '_setdiag', '_shape', '_sub_dense', '_sub_sparse', '_swap', '_validate_indices', '_with_data', '_zero_many', 'arcsin', 'arcsinh', 'arctan', 'arctanh', 'argmax', 'argmin', 'asformat', 'asfptype', 'astype', 'ceil', 'check_format', 'conj', 'conjugate', 'copy', 'count_nonzero', 'data', 'deg2rad', 'diagonal', 'dot', 'dtype', 'eliminate_zeros', 'expm1', 'floor', 'format', 'getH', 'get_shape', 'getcol', 'getformat', 'getmaxprint', 'getnnz', 'getrow', 'has_canonical_format', 'has_sorted_indices', 'indices', 'indptr', 'log1p', 'max', 'maximum', 'maxprint', 'mean', 'min', 'minimum', 'multiply', 'ndim', 'nnz', 'nonzero', 'power', 'prune', 'rad2deg', 'reshape', 'resize', 'rint', 'set_shape', 'setdiag', 'shape', 'sign', 'sin', 'sinh', 'sort_indices', 'sorted_indices', 'sqrt', 'sum', 'sum_duplicates', 'tan', 'tanh', 'toarray', 'tobsr', 'tocoo', 'tocsc', 'tocsr', 'todense', 'todia', 'todok', 'tolil', 'transpose', 'trunc']\n\n\n\n# shape of first row\nratings[0].shape\n\n(1, 100)\n\n\n\n# Accessing and shape of certain rows and columns\nprint(f'''\n    Row 1            dimension {ratings[0].shape}\n    Row 1 transposed dimension {ratings[0].T.shape}\n    Col 1            dimension {ratings[:, 0].shape}\n    Col 1 transposed dimension {ratings[:, 0].T.shape}\n    '''\n)\n\n\n    Row 1            dimension (1, 100)\n    Row 1 transposed dimension (100, 1)\n    Col 1            dimension (1000, 1)\n    Col 1 transposed dimension (1, 1000)\n    \n\n\n\n# Multiplying rows\nr1_norm2 = ratings[0].dot(ratings[0].T)\nprint(f'Inner product\\n\\t class: {type(r1_norm2)}\\n\\t shape: {r1_norm2.shape}\\n\\t value: {r1_norm2[0, 0]}')\n\nInner product\n     class: &lt;class 'scipy.sparse.csr.csr_matrix'&gt;\n     shape: (1, 1)\n     value: 88.0"
  },
  {
    "objectID": "code/resnick_1994/resnick_1994_demo.html#writting-a-similarity-method",
    "href": "code/resnick_1994/resnick_1994_demo.html#writting-a-similarity-method",
    "title": "User Collaborative Filtering",
    "section": "Writting a Similarity Method",
    "text": "Writting a Similarity Method\n\ndef similarity(u, v, method='cosine'):   \n    '''Return the similarity between entity u and v based on previous ratings\n\n    Args: \n        u (sparse array) - the ratings vector for entity u \n        v (sparse array) - the ratings vector for entity v \n        method (str) - the similarity methods (cosine, adjusted-cosine, pearson)\n\n    Returns: \n        float: A numerical score of the similarity between entities u and v ratings\n    '''\n    # format matrices\n    if method=='cosine':\n        sim = u.dot(v.T)[0,0] / (1e-5 +1.0 * np.sqrt(u.dot(u.T)[0,0] * v.dot(v.T)[0,0]))\n        return(sim)        \n\n    elif method=='pearson':\n        # center vectors \n        u_cen, v_cen = deepcopy(u), deepcopy(v)\n        u_cen.data -= u_cen.data.mean()\n        v_cen.data -= v_cen.data.mean()\n\n        # comptute similarity\n        sim = u_cen.dot(v_cen.T)[0,0] / (1e-5 + 1.0 * np.sqrt(u_cen.dot(u_cen.T)[0,0] * v_cen.dot(v_cen.T)[0,0]))\n        return(sim)\n\n    else: \n        return(\"Please use method = {'cosine', 'pearson'}\")\n\n\n# Examples! \nind1, ind2 = 0, 3\npearson = similarity(ratings[ind1], ratings[ind2], method='pearson')\ncosine = similarity(ratings[ind1], ratings[ind2], method='cosine')\n\nf'The pearson similarity is {np.round(pearson, 2)} and cosine similarity is {np.round(cosine, 2)}.'\n\n'The pearson similarity is -0.14 and cosine similarity is 0.0.'"
  },
  {
    "objectID": "code/resnick_1994/resnick_1994_demo.html#writting-a-hueristic-item-score-imputation",
    "href": "code/resnick_1994/resnick_1994_demo.html#writting-a-hueristic-item-score-imputation",
    "title": "User Collaborative Filtering",
    "section": "Writting a Hueristic Item Score Imputation",
    "text": "Writting a Hueristic Item Score Imputation\n\nx = ratings[0]\n\n\ny = x.nonzero()\n\nprint(x.nonzero())\n\n(array([0, 0, 0, 0], dtype=int32), array([16, 26, 38, 86], dtype=int32))\n\n\n\nnp.\n\narray([0, 0, 0, 0], dtype=int32)\n\n\n\ndef imputed_ratings(id, ratings, method = 'user-to-user', sim_method='cosine'):\n    '''Return the imputed ratings for unobserved-ratings for entity u\n\n    Args: \n        id (int) - id of the entity for the ratings vector to be applied for\n        ratings (sparse matrix) - the ratings matrix to apply CF towards\n        method (str) - the similarity methods (cosine, pearson)\n\n    Returns: \n        cf_ratings (np.array): An np array with imputed estimates of ratings for un-rated articles. \n    '''\n    \n    # find entity and items rated \n    id_vec = ratings[id] if method =='user-to-user' else ratings[:, id]\n    n_users, n_items = ratings.shape \n    entities_rated = id_vec.nonzero()\n    \n    # fetch entity tp entity to entity similarity\n    if method == 'user-to-user':\n        sims = [similarity(id_vec, ratings[i], method=sim_method) for i in range(n_users)]\n    elif method == 'item-to-item': \n        sims = [similarity(id_vec, ratings[:,i], method=sim_method) for i in range(n_items)]\n\n    # compute impute scores for all \n    if method == 'user-to-user': \n        cf_ratings = [ for ]"
  },
  {
    "objectID": "code/resnick_1994/resnick_1994_demo.html#generate-synthetic-data",
    "href": "code/resnick_1994/resnick_1994_demo.html#generate-synthetic-data",
    "title": "User Collaborative Filtering",
    "section": "Generate Synthetic Data",
    "text": "Generate Synthetic Data\n\n### Imports \nimport pandas as pd \nimport numpy as np\nfrom scipy import sparse  \nfrom copy import deepcopy\nimport matplotlib.pyplot as plt \n\n\n# Generate some fake rating data to play with \nn_users = 1_000 # number of users\nn_items = 100 # of items\nratings = sparse.random(n_users, n_items, density=0.10, format='csr', random_state=1985)\nratings.data = np.random.randint(0, 5, size=ratings.data.shape).astype(float)\n\n\n# example rating for a single row\nprint(ratings[0])\n\n  (0, 11)   3.0\n  (0, 16)   4.0\n  (0, 23)   4.0\n  (0, 26)   4.0\n  (0, 34)   1.0\n  (0, 38)   3.0\n  (0, 86)   4.0\n  (0, 89)   2.0\n  (0, 95)   0.0\n  (0, 98)   1.0"
  },
  {
    "objectID": "code/resnick_1994/resnick_1994_demo.html#user-to-user-cf-resnick-1994",
    "href": "code/resnick_1994/resnick_1994_demo.html#user-to-user-cf-resnick-1994",
    "title": "User Collaborative Filtering",
    "section": "User to User CF (Resnick 1994)",
    "text": "User to User CF (Resnick 1994)\n\ndef cf_user_to_user(id, ratings, sim_method='pearson'):\n    '''Return the imputed ratings for unobserved-ratings for entity u\n\n    Args: \n        id (int) - id of the entity for the ratings vector to be applied for\n        ratings (sparse matrix) - the ratings matrix to apply CF towards\n        method (str) - the similarity methods (cosine, pearson)\n\n    Returns: \n        cf_ratings (np.array): An np array with imputed estimates of ratings for un-rated articles. \n    '''\n    # fetch average user rating\n    n_users, n_items = ratings.shape\n    \n    # compute user-to-user similarity\n    sims = np.array([similarity(ratings[id], ratings[user]) for user in range(n_users)])\n    total_sim = np.sum(np.abs(sims))\n\n    # residualize ratings\n    ratings_resid = deepcopy(ratings)\n    ratings_resid.data = ratings_resid.data.astype(float)\n    for user in range(n_users): \n        ratings_resid[user].data -= ratings_resid[user].data.mean()\n    \n    # store previously rated item ratingss\n    cf_ratings = np.full(n_items, np.nan)\n    items_ranked = ratings[id].indices\n    cf_ratings[items_ranked] = ratings[id].data\n\n    # compute average rating for every item not ranked\n    unrated_items = np.setdiff1d(np.arange(n_items), items_ranked)\n    for item in unrated_items: \n        cf_ratings[item] = ratings[id].data.mean() + np.sum(sims * ratings[:,item])/total_sim\n\n    # return ratings\n    return(cf_ratings)\n\n\n\ncf_user_to_user(1, ratings)\n\narray([1.82957415, 1.82499751, 1.85299315, 1.87906179, 1.83613618,\n       1.86996127, 1.83657094, 1.8580771 , 1.94402725, 1.88251208,\n       1.87371842, 1.86202115, 1.8200888 , 1.8981778 , 1.91203758,\n       1.        , 1.86173336, 1.87208495, 1.86493801, 4.        ,\n       1.82864583, 1.86936068, 1.78605192, 1.86331963, 1.82654638,\n       1.92066823, 1.        , 3.        , 1.86705059, 0.        ,\n       1.8646681 , 1.        , 1.86397559, 1.81707945, 1.85286705,\n       1.82227709, 1.83254404, 1.85650547, 0.        , 1.89703854,\n       1.78317043, 1.90312655, 1.89427064, 1.89091876, 1.82548385,\n       1.81282133, 1.82874793, 1.88443935, 1.86564691, 1.84104925,\n       1.        , 1.90751662, 1.85747663, 1.95335813, 0.        ,\n       1.89969457, 1.84086516, 1.84756262, 1.83743379, 2.        ,\n       1.82107291, 1.84559239, 1.90879037, 1.81514726, 1.84039083,\n       1.88859077, 1.90118094, 1.84929746, 1.83720612, 1.86472832,\n       2.        , 1.88060354, 1.90305685, 1.89286469, 1.88215981,\n       1.86623908, 1.87150958, 3.        , 1.87675678, 1.80639099,\n       1.93212828, 1.84710448, 1.85277036, 1.85924812, 4.        ,\n       4.        , 1.90331998, 0.        , 1.85558737, 1.84610447,\n       1.85985853, 1.85272794, 1.81752903, 1.88978615, 1.89229447,\n       1.        , 1.85638961, 1.88321569, 1.86705772, 1.87842497])\n\n\n\nimport numpy as np\nfrom scipy import sparse  \nfrom copy import deepcopy\n\nclass CollabFilter(): \n    def __init__(self): \n        self.n_items = None\n        self.n_users = None\n        self.ratings = None\n        self.cf_ratings = None \n\n    def generate_data(self, n_users, n_items, density=0.1, random_state=1985): \n        \"\"\"\n        Generate a random sparse ratings matrix.\n        \"\"\"\n        # initialize\n        self.n_users = n_users\n        self.n_items = n_items\n\n        # set up random generate \n        rng = np.random.default_rng(random_state)\n        self.ratings = sparse.random(n_users, n_items, density=density, format='csr', random_state=rng)\n        self.ratings.data = rng.integers(1, 6, size=self.ratings.data.shape).astype(float)\n\n    def load_data(self, ratings):\n        \"\"\"\n        Load an external sparse matrix as the ratings matrix.\n        \"\"\"\n        if not isinstance(ratings, scipy.sparse.csr.csr_matrix): \n            raise ValueError(\"Ratings must be a scipy.sparse.csr_matrix.\")\n        \n        self.n_users, self.n_items = ratings.shape\n        self.ratings = ratings \n        \n    @staticmethod \n    def similarity(u, v, method='cosine'):   \n        '''Return the similarity between entity u and v based on previous ratings\n\n        Args: \n            u (sparse array) - the ratings vector for entity u \n            v (sparse array) - the ratings vector for entity v \n            method (str) - the similarity methods (cosine, adjusted-cosine, pearson)\n\n        Returns: \n            float: A numerical score of the similarity between entities u and v ratings\n        '''\n        # format matrices\n        if method=='cosine':\n            # compute l2-norms \n            u_norm = np.sqrt(u.dot(u.T)[0,0])\n            v_norm = np.sqrt(v.dot(v.T)[0,0])\n\n            # return similarity\n            if u_norm == 0.0 or v_norm == 0.0: \n                return(0.0)\n            return u.dot(v.T)[0,0] / (u_norm * v_norm) \n\n        elif method=='pearson':\n            # center vectors \n            u_cen, v_cen = deepcopy(u), deepcopy(v)\n            u_cen.data -= u_cen.data.mean()\n            v_cen.data -= v_cen.data.mean()\n\n            # comptute similarity\n            sim = u_cen.dot(v_cen.T)[0,0] / (1e-5 + 1.0 * np.sqrt(u_cen.dot(u_cen.T)[0,0] * v_cen.dot(v_cen.T)[0,0]))\n            return(sim)\n\n        else: \n            raise ValueError(\"Please use method = {'cosine', 'pearson'}\")\n        \n\n    def collaborative_filter(self, id, ratings, cf_method='user-to-user', sim_method='pearson'):\n        '''Return the imputed ratings for unobserved-ratings for entity u\n\n        Args: \n            id (int) - id of the entity for the ratings vector to be applied for\n            ratings (sparse matrix) - the ratings matrix to apply CF towards\n            method (str) - the similarity methods (cosine, pearson)\n\n        Returns: \n            cf_ratings (np.array): An np array with imputed estimates of ratings for un-rated articles. \n        '''\n        if self.ratings is None:\n            raise ValueError(\"Ratings matrix not initialized. Use generate_data or load_data.\")\n\n        if not (0 &lt;= id &lt; self.n_users):\n            raise ValueError(f\"Invalid user ID. Must be in range [0, {self.n_users - 1}].\")\n\n        # compute user-to-user similarity\n        sims = np.array([self.similarity(self.ratings[id], self.ratings[user]) for user in range(self.n_users)])\n        total_sim = np.sum(np.abs(sims))\n\n        # residualize ratings\n        ratings_resid = deepcopy(self.ratings)\n        ratings_resid.data = ratings_resid.data.astype(float)\n        for user in range(self.n_users): \n            ratings_resid[user].data -= ratings_resid[user].data.mean()\n        \n        # store previously rated item ratings\n        self.cf_ratings = np.full(self.n_items, np.nan)\n        items_ranked = self.ratings[id].indices\n        self.cf_ratings[items_ranked] = self.ratings[id].data\n\n        # compute average rating for every item not ranked\n        unrated_items = np.setdiff1d(np.arange(self.n_items), items_ranked)\n        for item in unrated_items: \n            self.cf_ratings[item] = ratings[id].data.mean() + np.sum(sims * self.ratings[:,item])/total_sim\n\n        return(1)\n\n    \n\n\n  File \"&lt;tokenize&gt;\", line 19\n    self.n_users = n_users\n    ^\nIndentationError: unindent does not match any outer indentation level"
  },
  {
    "objectID": "blog/blog_posts/resnick_1994/index.html",
    "href": "blog/blog_posts/resnick_1994/index.html",
    "title": "Paper Notes - GroupLens: An Open Architecture for Collaborative Filtering of Netnews",
    "section": "",
    "text": "The GroupLens: An Open Architecture for Collaborative Filtering of Netnews paper was one of the first papers to introduce collaborative filtering for recommendation applications in 1994. The paper focuses on not just the recommendation problem but also how those recommendations are integrated into the Usenet Netnews network, displayed to users, and implications for serving personalized news to users."
  },
  {
    "objectID": "blog/blog_posts/resnick_1994/index.html#collaborative-filtering",
    "href": "blog/blog_posts/resnick_1994/index.html#collaborative-filtering",
    "title": "Paper Notes - GroupLens: An Open Architecture for Collaborative Filtering of Netnews",
    "section": "Collaborative Filtering",
    "text": "Collaborative Filtering\nFor each user \\(u\\in\\mathcal{U}\\) and item \\(v\\in\\mathcal{V}\\) we assign the rating \\(u\\) assigns to \\(v\\) as \\(R_{uv}\\). Supposing \\(\\mid\\mathcal{U}\\mid = n\\) and \\(\\mid\\mathcal{V}\\mid = m\\) the ratings matrix \\(\\mathbf{R}\\in\\mathbb{R}^{n\\times m}\\) with\n\\[\n\\mathbf{R} = \\begin{bmatrix}\nR_{11} & \\dots & R_{1m}\\\\\nR_{21} & \\dots & R_{2m}\\\\\n\\vdots & \\ddots & \\vdots\\\\\nR_{n1} & \\dots & R_{nm}\n\\end{bmatrix}\n\\]\nNow, several entries in \\(\\mathbf{R}\\) will be missing as not every (user, item) pair will be rated.\nThe authors impute this missing scores based on the hueristic that “people who agreed in the past are likely to agree again.” To impute the missing rating \\(R_{uv}\\) they follow:\n\nUnderstand how similar user \\(u\\) is to all other users.\nScore the item \\(v\\) based on previous ratings of other users on \\(v\\) taking into account how similar the user is to \\(u\\).\n\nThis manifests in the scoring equation \\[\n\\hat{R}_{uv} = \\bar{R_u} + \\frac{\\sum_{s\\neq u} \\text{sim}(u, s)(R_{iv} - \\bar{R}_i)}{\\sum_{s\\neq u} |\\text{sim}(u, s)|}\n\\]\nHere, we first residualize all ratings relative to the user’s average rating. This removes any user-level bias or different interpretations of the rating scale. From here, we simply take a weighted sum of the ratings on item \\(v\\) for each user, weighted by the similarity between the user providing that rating \\(i\\) and user \\(u\\). The authors propose to model user-to-user similarity using simple correlation scores:\n\\[\n\\text{sim}(u, s) = \\frac{\\sum_{j=1}^m(R_{uj} - \\bar{R}_{u})(R_{sj} - \\bar{R}_{s})}{\\sqrt{\\sum_{j=1}^m(R_{uj} - \\bar{R}_{u})^2}\\sqrt{\\sum_{j=1}^m(R_{sj} - \\bar{R}_{s})^2}} \\in [-1, 1]\n\\]\nIn both of these equations, if \\(R_{uv}\\) is unobserved, then that term in the summand is removed. Therefore, if two users \\((u, s)\\) do not score any of the same items, their similarity is set to zero and user \\(s\\) ratings do not impact the rating estimates for user \\(u\\).\nThis approach is typically referred to user-collaborative filtering (since we measure user-to-user similarity) in modern applications and similar approaches for item-collaborative filtering"
  },
  {
    "objectID": "blog/blog_posts/resnick_1994/index.html#collaborative-filtering---extensions",
    "href": "blog/blog_posts/resnick_1994/index.html#collaborative-filtering---extensions",
    "title": "Paper Notes - GroupLens: An Open Architecture for Collaborative Filtering of Netnews",
    "section": "Collaborative Filtering - Extensions",
    "text": "Collaborative Filtering - Extensions\nThe authors point out a number of limitations with this approach which are approached with newer methodologies but crucially they discuss:\n\nThis method does not utilize implicit feedback\nThis method does not utilize features of the users or items\nSimilarity scoring across all users will not scale"
  }
]