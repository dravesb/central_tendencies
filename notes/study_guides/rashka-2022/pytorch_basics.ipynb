{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ~~Creating and manipulating tensors~~\n",
    "- Dataset, Dataloader, TensorDataset\n",
    "- Building a lightweight example [save this for chp 13?]\n",
    "\n",
    "Chp 13: Going Deeper - mechanics of PyTorch \n",
    "\n",
    "- Computational Graphs and Auograd \n",
    "- Modules: Torch.nn: nn.Sequenetial, nn.Module \n",
    "- Custom Layers using nn.Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pytorch is built on _tensors_ which are enriched arrays containing data and model parameters.\n",
    "* You can create _tensors_ from \n",
    "    * lists\n",
    "    * _numpy_ arrays\n",
    "    * Using built in initialization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list: tensor([1, 2, 3])\n",
      "numpy: tensor([4, 5, 6], dtype=torch.int32)\n",
      "ones: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "rand: tensor([[0.3651, 0.4031, 0.1296],\n",
      "        [0.0609, 0.5880, 0.4440]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/r5j2k3qx1fl3wlj7tn5574rm0000gn/T/ipykernel_68406/2435939936.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t_b = torch.tensor(b)\n",
      "/var/folders/s7/r5j2k3qx1fl3wlj7tn5574rm0000gn/T/ipykernel_68406/2435939936.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t_c = torch.tensor(c)\n",
      "/var/folders/s7/r5j2k3qx1fl3wlj7tn5574rm0000gn/T/ipykernel_68406/2435939936.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t_d = torch.tensor(d)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# from list\n",
    "a = [1, 2, 3]\n",
    "t_a = torch.tensor(a)\n",
    "print(f\"list: {t_a}\")\n",
    "\n",
    "# from numpy\n",
    "b = torch.from_numpy(np.array([4, 5, 6], dtype=np.int32))\n",
    "t_b = torch.tensor(b)\n",
    "print(f\"numpy: {t_b}\")\n",
    "\n",
    "# from ones\n",
    "c = torch.ones(2, 3)\n",
    "t_c = torch.tensor(c)\n",
    "print(f\"ones: {t_c}\")\n",
    "\n",
    "# from ones\n",
    "torch.manual_seed(1985)\n",
    "d = torch.rand(2, 3)\n",
    "t_d = torch.tensor(d)\n",
    "print(f\"rand: {t_d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access elements of the tensor using standard _.loc()_ accessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      x: tensor([[0.3651, 0.4031, 0.1296],\n",
      "        [0.0609, 0.5880, 0.4440]])\n",
      "      shape: torch.Size([2, 3])\n",
      "      first row: tensor([0.3651, 0.4031, 0.1296])\n",
      "      first column: tensor([0.3651, 0.0609])\n",
      "      last element: 0.4439687728881836\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1985)\n",
    "x = torch.rand(2, 3)\n",
    "\n",
    "print(f\"\"\"\n",
    "      x: {x}\n",
    "      shape: {x.shape}\n",
    "      first row: {x[0, :]}\n",
    "      first column: {x[:, 0]}\n",
    "      last element: {x[-1, -1]}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can manipulate data types using _torch.to_: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "t_a_new = t_a.to(torch.int64)\n",
    "print(t_a_new.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can reshape and transpose tensors using _torch.reshape()_ and _torch.transpose()_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5]) --> torch.Size([5, 3])\n",
      "torch.Size([30]) --> torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "# transpose\n",
    "t = torch.rand(3, 5)\n",
    "t_tr = t.transpose(0, 1)  # which two dimensions to transpose\n",
    "print(t.shape, \"-->\", t_tr.shape)\n",
    "\n",
    "# reshape\n",
    "t = torch.zeros(30)\n",
    "t_rs = t.reshape(5, 6)  # which two dimensions to transpose\n",
    "print(t.shape, \"-->\", t_rs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_torch.squeeze()_ drops all dimensions of a tensor that are redudant to reduce its rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsqueezed: tensor([[[1., 1.]]])\n",
      "squeezed: tensor([1., 1.])\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(1, 1, 2)\n",
    "print(f\"unsqueezed: {t}\")\n",
    "t_sqz = t.squeeze()  # removes redundant ranks\n",
    "print(f\"squeezed: {t_sqz}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear algebraic operations are supported including \n",
    "    * vector/matrix multiplication \n",
    "    * statistical summaries (mean, standard deviation, etc) across axes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mul: torch.Size([5, 2])\n",
      "inner: torch.Size([2, 2]), outer: torch.Size([5, 5])\n",
      "row_means: tensor([-0.2318, -0.8095,  0.0320, -0.2714, -0.3531])\n",
      "row_stds: tensor([0.0538, 0.0972, 0.2037, 0.8031, 0.5477])\n"
     ]
    }
   ],
   "source": [
    "# generate some data\n",
    "torch.manual_seed(1985)\n",
    "x = 2.0 * torch.rand(5, 2) - 1.0\n",
    "y = torch.normal(mean=0.5, std=0.1, size=(5, 2))\n",
    "\n",
    "# element-wise multiplication\n",
    "mul = x * y\n",
    "print(f\"mul: {mul.shape}\")\n",
    "\n",
    "# matrix multiplication\n",
    "inner = torch.mm(x.transpose(0, 1), y)\n",
    "outter = torch.mm(x, y.transpose(0, 1))\n",
    "print(f\"inner: {inner.shape}, outer: {outter.shape}\")\n",
    "\n",
    "# row means and standard deviation\n",
    "row_means = x.mean(dim=1)\n",
    "row_stds = x.std(dim=1)\n",
    "print(f\"row_means: {row_means}\\nrow_stds: {row_stds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also combine and manipulate tensors utilizing either: \n",
    "* Chunking - spliting the tensor into equal sizes (if possible)\n",
    "* Splitting - splitting the tensor into specified sizes (must be _exact_)\n",
    "* Concatenating - combining tensors along an existing dimension\n",
    "* Stacking - creates a new tensor by adding new dimensions to an existing tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([[0.3651, 0.4031],\n",
      "        [0.1296, 0.0609],\n",
      "        [0.5880, 0.4440],\n",
      "        [0.6482, 0.0804]])\n",
      "--- CHUNKING --- \n",
      "[[0.36506873 0.40311843]\n",
      " [0.12958086 0.06087303]]\n",
      "[[0.5880055  0.44396877]\n",
      " [0.64821994 0.08037758]]\n",
      "\n",
      "--- SPLITTING --- \n",
      "[[0.36506873 0.40311843]\n",
      " [0.12958086 0.06087303]]\n",
      "[[0.5880055  0.44396877]\n",
      " [0.64821994 0.08037758]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the data\n",
    "torch.manual_seed(1985)\n",
    "t = torch.rand(4, 2)\n",
    "print(f\"t: {t}\")\n",
    "\n",
    "# chunking\n",
    "print(\"--- CHUNKING --- \")\n",
    "t_splits = torch.chunk(t, 2, dim=0)\n",
    "[print(item.numpy()) for item in t_splits]\n",
    "\n",
    "# splitting\n",
    "print(\"\\n--- SPLITTING --- \")\n",
    "t_splits = torch.split(t, split_size_or_sections=[2, 2], dim=0)\n",
    "[print(item.numpy()) for item in t_splits]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenation: tensor([1., 1., 1., 1., 1., 1.])\n",
      "Stacking: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# concatenation\n",
    "x = torch.ones(3)\n",
    "y = torch.ones(3)\n",
    "z = torch.cat([x, y], axis=0)\n",
    "print(f\"Concatenation: {z}\")\n",
    "\n",
    "# stacking\n",
    "z = torch.stack([x, y], axis=0)\n",
    "print(f\"Stacking: {z}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few popular ways to build datasets. We'll focus on three primarily: \n",
    "\n",
    "* _Dataset_ stores samples and labels. \n",
    "* _TensorDataSet_ is a _Dataset_ build directly from torch tensors (typical for tabular ML) \n",
    "* _DataLoader_ loads provides an iterable on _Dataset_ that allows you to load data in batches, shuffle samples, and load data in batches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational Graphs and Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### PyTorch Training Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3927148816.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[49], line 16\u001b[0;36m\u001b[0m\n\u001b[0;31m    # 7. Accumulate the performance metrics for the epoch\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1 \n",
    "for epoch in range(n_epochs):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # 1. generate predictions \n",
    "        \n",
    "        # 2. calculate the loss \n",
    "        \n",
    "        # 3. back propogate loss \n",
    "        \n",
    "        # 4. update the weights\n",
    "        \n",
    "        # 5. reset the gradients to zero\n",
    "        \n",
    "        # 6. log the updated performance\n",
    "    \n",
    "    # 7. Accumulate the performance metrics for the epoch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
