{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script accommodates implementation of user-collaborative filtering from the original GroupLens paper ([Resnick et al 1994](http://dx.doi.org/10.1145/192844.192905)).\n",
    "See here for a full write up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from scipy import sparse  \n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some fake rating data to play with \n",
    "n_users = 1_000 # number of users\n",
    "n_items = 100 # of items\n",
    "ratings = sparse.random(n_users, n_items, density=0.10, format='csr', random_state=1985)\n",
    "ratings.data = np.random.randint(0, 5, size=ratings.data.shape).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 11)\t3.0\n",
      "  (0, 16)\t4.0\n",
      "  (0, 23)\t4.0\n",
      "  (0, 26)\t4.0\n",
      "  (0, 34)\t1.0\n",
      "  (0, 38)\t3.0\n",
      "  (0, 86)\t4.0\n",
      "  (0, 89)\t2.0\n",
      "  (0, 95)\t0.0\n",
      "  (0, 98)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# example rating for a single row\n",
    "print(ratings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abs__', '__add__', '__array_priority__', '__bool__', '__class__', '__delattr__', '__dict__', '__dir__', '__div__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__idiv__', '__imul__', '__init__', '__init_subclass__', '__isub__', '__iter__', '__itruediv__', '__le__', '__len__', '__lt__', '__matmul__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__pow__', '__radd__', '__rdiv__', '__reduce__', '__reduce_ex__', '__repr__', '__rmatmul__', '__rmul__', '__round__', '__rsub__', '__rtruediv__', '__setattr__', '__setitem__', '__sizeof__', '__slotnames__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__weakref__', '_add_dense', '_add_sparse', '_arg_min_or_max', '_arg_min_or_max_axis', '_asindices', '_binopt', '_cs_matrix__get_has_canonical_format', '_cs_matrix__get_sorted', '_cs_matrix__set_has_canonical_format', '_cs_matrix__set_sorted', '_deduped_data', '_divide', '_divide_sparse', '_get_arrayXarray', '_get_arrayXint', '_get_arrayXslice', '_get_columnXarray', '_get_dtype', '_get_intXarray', '_get_intXint', '_get_intXslice', '_get_sliceXarray', '_get_sliceXint', '_get_sliceXslice', '_get_submatrix', '_imag', '_inequality', '_insert_many', '_major_index_fancy', '_major_slice', '_maximum_minimum', '_min_or_max', '_min_or_max_axis', '_minor_index_fancy', '_minor_reduce', '_minor_slice', '_mul_multivector', '_mul_scalar', '_mul_sparse_matrix', '_mul_vector', '_prepare_indices', '_process_toarray_args', '_real', '_rsub_dense', '_scalar_binopt', '_set_arrayXarray', '_set_arrayXarray_sparse', '_set_dtype', '_set_intXint', '_set_many', '_set_self', '_setdiag', '_shape', '_sub_dense', '_sub_sparse', '_swap', '_validate_indices', '_with_data', '_zero_many', 'arcsin', 'arcsinh', 'arctan', 'arctanh', 'argmax', 'argmin', 'asformat', 'asfptype', 'astype', 'ceil', 'check_format', 'conj', 'conjugate', 'copy', 'count_nonzero', 'data', 'deg2rad', 'diagonal', 'dot', 'dtype', 'eliminate_zeros', 'expm1', 'floor', 'format', 'getH', 'get_shape', 'getcol', 'getformat', 'getmaxprint', 'getnnz', 'getrow', 'has_canonical_format', 'has_sorted_indices', 'indices', 'indptr', 'log1p', 'max', 'maximum', 'maxprint', 'mean', 'min', 'minimum', 'multiply', 'ndim', 'nnz', 'nonzero', 'power', 'prune', 'rad2deg', 'reshape', 'resize', 'rint', 'set_shape', 'setdiag', 'shape', 'sign', 'sin', 'sinh', 'sort_indices', 'sorted_indices', 'sqrt', 'sum', 'sum_duplicates', 'tan', 'tanh', 'toarray', 'tobsr', 'tocoo', 'tocsc', 'tocsr', 'todense', 'todia', 'todok', 'tolil', 'transpose', 'trunc']\n"
     ]
    }
   ],
   "source": [
    "print(dir(ratings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of first row\n",
    "ratings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Row 1            dimension (1, 100)\n",
      "    Row 1 transposed dimension (100, 1)\n",
      "    Col 1            dimension (1000, 1)\n",
      "    Col 1 transposed dimension (1, 1000)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Accessing and shape of certain rows and columns\n",
    "print(f'''\n",
    "    Row 1            dimension {ratings[0].shape}\n",
    "    Row 1 transposed dimension {ratings[0].T.shape}\n",
    "    Col 1            dimension {ratings[:, 0].shape}\n",
    "    Col 1 transposed dimension {ratings[:, 0].T.shape}\n",
    "    '''\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner product\n",
      "\t class: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "\t shape: (1, 1)\n",
      "\t value: 88.0\n"
     ]
    }
   ],
   "source": [
    "# Multiplying rows\n",
    "r1_norm2 = ratings[0].dot(ratings[0].T)\n",
    "print(f'Inner product\\n\\t class: {type(r1_norm2)}\\n\\t shape: {r1_norm2.shape}\\n\\t value: {r1_norm2[0, 0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writting a Similarity Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(u, v, method='cosine'):   \n",
    "    '''Return the similarity between entity u and v based on previous ratings\n",
    "\n",
    "    Args: \n",
    "        u (sparse array) - the ratings vector for entity u \n",
    "        v (sparse array) - the ratings vector for entity v \n",
    "        method (str) - the similarity methods (cosine, adjusted-cosine, pearson)\n",
    "\n",
    "    Returns: \n",
    "        float: A numerical score of the similarity between entities u and v ratings\n",
    "    '''\n",
    "    # format matrices\n",
    "    if method=='cosine':\n",
    "        sim = u.dot(v.T)[0,0] / (1e-5 +1.0 * np.sqrt(u.dot(u.T)[0,0] * v.dot(v.T)[0,0]))\n",
    "        return(sim)        \n",
    "\n",
    "    elif method=='pearson':\n",
    "        # center vectors \n",
    "        u_cen, v_cen = deepcopy(u), deepcopy(v)\n",
    "        u_cen.data -= u_cen.data.mean()\n",
    "        v_cen.data -= v_cen.data.mean()\n",
    "\n",
    "        # comptute similarity\n",
    "        sim = u_cen.dot(v_cen.T)[0,0] / (1e-5 + 1.0 * np.sqrt(u_cen.dot(u_cen.T)[0,0] * v_cen.dot(v_cen.T)[0,0]))\n",
    "        return(sim)\n",
    "\n",
    "    else: \n",
    "        return(\"Please use method = {'cosine', 'pearson'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The pearson similarity is -0.14 and cosine similarity is 0.0.'"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examples! \n",
    "ind1, ind2 = 0, 3\n",
    "pearson = similarity(ratings[ind1], ratings[ind2], method='pearson')\n",
    "cosine = similarity(ratings[ind1], ratings[ind2], method='cosine')\n",
    "\n",
    "f'The pearson similarity is {np.round(pearson, 2)} and cosine similarity is {np.round(cosine, 2)}.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User to User CF (Resnick 1994)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cf_user_to_user(id, ratings, sim_method='pearson'):\n",
    "    '''Return the imputed ratings for unobserved-ratings for entity u\n",
    "\n",
    "    Args: \n",
    "        id (int) - id of the entity for the ratings vector to be applied for\n",
    "        ratings (sparse matrix) - the ratings matrix to apply CF towards\n",
    "        method (str) - the similarity methods (cosine, pearson)\n",
    "\n",
    "    Returns: \n",
    "        cf_ratings (np.array): An np array with imputed estimates of ratings for un-rated articles. \n",
    "    '''\n",
    "    # fetch average user rating\n",
    "    n_users, n_items = ratings.shape\n",
    "    \n",
    "    # compute user-to-user similarity\n",
    "    sims = np.array([similarity(ratings[id], ratings[user]) for user in range(n_users)])\n",
    "    total_sim = np.sum(np.abs(sims))\n",
    "\n",
    "    # residualize ratings\n",
    "    ratings_resid = deepcopy(ratings)\n",
    "    ratings_resid.data = ratings_resid.data.astype(float)\n",
    "    for user in range(n_users): \n",
    "        ratings_resid[user].data -= ratings_resid[user].data.mean()\n",
    "    \n",
    "    # store previously rated item ratingss\n",
    "    cf_ratings = np.full(n_items, np.nan)\n",
    "    items_ranked = ratings[id].indices\n",
    "    cf_ratings[items_ranked] = ratings[id].data\n",
    "\n",
    "    # compute average rating for every item not ranked\n",
    "    unrated_items = np.setdiff1d(np.arange(n_items), items_ranked)\n",
    "    for item in unrated_items: \n",
    "        cf_ratings[item] = ratings[id].data.mean() + np.sum(sims * ratings[:,item])/total_sim\n",
    "\n",
    "    # return ratings\n",
    "    return(cf_ratings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.82957415, 1.82499751, 1.85299315, 1.87906179, 1.83613618,\n",
       "       1.86996127, 1.83657094, 1.8580771 , 1.94402725, 1.88251208,\n",
       "       1.87371842, 1.86202115, 1.8200888 , 1.8981778 , 1.91203758,\n",
       "       1.        , 1.86173336, 1.87208495, 1.86493801, 4.        ,\n",
       "       1.82864583, 1.86936068, 1.78605192, 1.86331963, 1.82654638,\n",
       "       1.92066823, 1.        , 3.        , 1.86705059, 0.        ,\n",
       "       1.8646681 , 1.        , 1.86397559, 1.81707945, 1.85286705,\n",
       "       1.82227709, 1.83254404, 1.85650547, 0.        , 1.89703854,\n",
       "       1.78317043, 1.90312655, 1.89427064, 1.89091876, 1.82548385,\n",
       "       1.81282133, 1.82874793, 1.88443935, 1.86564691, 1.84104925,\n",
       "       1.        , 1.90751662, 1.85747663, 1.95335813, 0.        ,\n",
       "       1.89969457, 1.84086516, 1.84756262, 1.83743379, 2.        ,\n",
       "       1.82107291, 1.84559239, 1.90879037, 1.81514726, 1.84039083,\n",
       "       1.88859077, 1.90118094, 1.84929746, 1.83720612, 1.86472832,\n",
       "       2.        , 1.88060354, 1.90305685, 1.89286469, 1.88215981,\n",
       "       1.86623908, 1.87150958, 3.        , 1.87675678, 1.80639099,\n",
       "       1.93212828, 1.84710448, 1.85277036, 1.85924812, 4.        ,\n",
       "       4.        , 1.90331998, 0.        , 1.85558737, 1.84610447,\n",
       "       1.85985853, 1.85272794, 1.81752903, 1.88978615, 1.89229447,\n",
       "       1.        , 1.85638961, 1.88321569, 1.86705772, 1.87842497])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_user_to_user(1, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    self.n_users = n_users\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse  \n",
    "from copy import deepcopy\n",
    "\n",
    "class CollabFilter(): \n",
    "    def __init__(self): \n",
    "        self.n_items = None\n",
    "        self.n_users = None\n",
    "        self.ratings = None\n",
    "        self.cf_ratings = None \n",
    "\n",
    "    def generate_data(self, n_users, n_items, density=0.1, random_state=1985): \n",
    "        \"\"\"\n",
    "        Generate a random sparse ratings matrix.\n",
    "        \"\"\"\n",
    "        # initialize\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "\n",
    "        # set up random generate \n",
    "        rng = np.random.default_rng(random_state)\n",
    "        self.ratings = sparse.random(n_users, n_items, density=density, format='csr', random_state=rng)\n",
    "        self.ratings.data = rng.integers(1, 6, size=self.ratings.data.shape).astype(float)\n",
    "\n",
    "    def load_data(self, ratings):\n",
    "        \"\"\"\n",
    "        Load an external sparse matrix as the ratings matrix.\n",
    "        \"\"\"\n",
    "        if not isinstance(ratings, scipy.sparse.csr.csr_matrix): \n",
    "            raise ValueError(\"Ratings must be a scipy.sparse.csr_matrix.\")\n",
    "        \n",
    "        self.n_users, self.n_items = ratings.shape\n",
    "        self.ratings = ratings \n",
    "        \n",
    "    @staticmethod \n",
    "    def similarity(u, v, method='cosine'):   \n",
    "        '''Return the similarity between entity u and v based on previous ratings\n",
    "\n",
    "        Args: \n",
    "            u (sparse array) - the ratings vector for entity u \n",
    "            v (sparse array) - the ratings vector for entity v \n",
    "            method (str) - the similarity methods (cosine, adjusted-cosine, pearson)\n",
    "\n",
    "        Returns: \n",
    "            float: A numerical score of the similarity between entities u and v ratings\n",
    "        '''\n",
    "        # format matrices\n",
    "        if method=='cosine':\n",
    "            # compute l2-norms \n",
    "            u_norm = np.sqrt(u.dot(u.T)[0,0])\n",
    "            v_norm = np.sqrt(v.dot(v.T)[0,0])\n",
    "\n",
    "            # return similarity\n",
    "            if u_norm == 0.0 or v_norm == 0.0: \n",
    "                return(0.0)\n",
    "            return u.dot(v.T)[0,0] / (u_norm * v_norm) \n",
    "\n",
    "        elif method=='pearson':\n",
    "            # center vectors \n",
    "            u_cen, v_cen = deepcopy(u), deepcopy(v)\n",
    "            u_cen.data -= u_cen.data.mean()\n",
    "            v_cen.data -= v_cen.data.mean()\n",
    "\n",
    "            # comptute similarity\n",
    "            sim = u_cen.dot(v_cen.T)[0,0] / (1e-5 + 1.0 * np.sqrt(u_cen.dot(u_cen.T)[0,0] * v_cen.dot(v_cen.T)[0,0]))\n",
    "            return(sim)\n",
    "\n",
    "        else: \n",
    "            raise ValueError(\"Please use method = {'cosine', 'pearson'}\")\n",
    "        \n",
    "\n",
    "    def collaborative_filter(self, id, ratings, cf_method='user-to-user', sim_method='pearson'):\n",
    "        '''Return the imputed ratings for unobserved-ratings for entity u\n",
    "\n",
    "        Args: \n",
    "            id (int) - id of the entity for the ratings vector to be applied for\n",
    "            ratings (sparse matrix) - the ratings matrix to apply CF towards\n",
    "            method (str) - the similarity methods (cosine, pearson)\n",
    "\n",
    "        Returns: \n",
    "            cf_ratings (np.array): An np array with imputed estimates of ratings for un-rated articles. \n",
    "        '''\n",
    "        if self.ratings is None:\n",
    "            raise ValueError(\"Ratings matrix not initialized. Use generate_data or load_data.\")\n",
    "\n",
    "        if not (0 <= id < self.n_users):\n",
    "            raise ValueError(f\"Invalid user ID. Must be in range [0, {self.n_users - 1}].\")\n",
    "\n",
    "        # compute user-to-user similarity\n",
    "        sims = np.array([self.similarity(self.ratings[id], self.ratings[user]) for user in range(self.n_users)])\n",
    "        total_sim = np.sum(np.abs(sims))\n",
    "\n",
    "        # residualize ratings\n",
    "        ratings_resid = deepcopy(self.ratings)\n",
    "        ratings_resid.data = ratings_resid.data.astype(float)\n",
    "        for user in range(self.n_users): \n",
    "            ratings_resid[user].data -= ratings_resid[user].data.mean()\n",
    "        \n",
    "        # store previously rated item ratings\n",
    "        self.cf_ratings = np.full(self.n_items, np.nan)\n",
    "        items_ranked = self.ratings[id].indices\n",
    "        self.cf_ratings[items_ranked] = self.ratings[id].data\n",
    "\n",
    "        # compute average rating for every item not ranked\n",
    "        unrated_items = np.setdiff1d(np.arange(self.n_items), items_ranked)\n",
    "        for item in unrated_items: \n",
    "            self.cf_ratings[item] = ratings[id].data.mean() + np.sum(sims * self.ratings[:,item])/total_sim\n",
    "\n",
    "        return(1)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
