<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Chapter 14: Classifying Images with Deep CNNs – Central Tendencies</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-a7555b885b8adab05db87d056733f163.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Central Tendencies</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../blog/blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About Me</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/dravesb"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/benjamin-draves-347893167"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.strava.com/athletes/19369962"> <i class="bi bi-strava" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.goodreads.com/user/show/62018665-benjamin-draves"> <i class="bi bi-book" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#understanding-convolutions" id="toc-understanding-convolutions" class="nav-link active" data-scroll-target="#understanding-convolutions">Understanding Convolutions</a></li>
  <li><a href="#performing-2d-convolutions" id="toc-performing-2d-convolutions" class="nav-link" data-scroll-target="#performing-2d-convolutions">Performing 2D Convolutions</a></li>
  <li><a href="#subsampling-layers" id="toc-subsampling-layers" class="nav-link" data-scroll-target="#subsampling-layers">Subsampling Layers</a></li>
  <li><a href="#implementing-a-cnn" id="toc-implementing-a-cnn" class="nav-link" data-scroll-target="#implementing-a-cnn">Implementing a CNN</a></li>
  <li><a href="#implementing-a-cnn-with-pytorch" id="toc-implementing-a-cnn-with-pytorch" class="nav-link" data-scroll-target="#implementing-a-cnn-with-pytorch">Implementing a CNN with PyTorch</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Chapter 14: Classifying Images with Deep CNNs</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Chapter layout:</p>
<ol type="1">
<li>Understanding Convolutions</li>
<li>Implementing a CNN</li>
<li>Implementing a Deep CNN with PyTorch</li>
<li>Smile Classification using a CNN</li>
</ol>
<section id="understanding-convolutions" class="level3">
<h3 class="anchored" data-anchor-id="understanding-convolutions">Understanding Convolutions</h3>
<ul>
<li>CNNs are a family of models that were inspired from the visual cortext of the human brain.
<ul>
<li>Neurons responds differently to light: the primary layer detects edges, higher order layers detect shapes and patterns</li>
</ul></li>
<li>Orginalally developed by Yann LeCun and colleagues in the 1990s</li>
<li>CNNs are usually refered to as <em>feature extraction layers</em></li>
</ul>
<p>CNNs are usually thought of as feature extraction layers that are able to extract low-level features in the early layers which are utilized later in the network to detect patterns between these features and the target variable of interest.</p>
<p>CNNs construct a <em>feature hierachy</em> by combining low-level features to form high-level features.</p>
<p>CNN computes <em>feature maps</em> from an input image to create a feature. They look over <em>local receptive fields</em> = local patch of pixels to construct and pool features in small areas of the image.</p>
<p>This method relies on * sparse connectivity = an element of a feature map is only connected to its nearest neighbor * parameter sharing = by learning a common set of parameters in a patch, we can utilize it in different parts of the image</p>
<p>Typically a CNN is constructed of</p>
<ol type="1">
<li>Several <em>convolutional</em> layers</li>
<li>Subsampling / Pooling layers
<ul>
<li>These don’t have any weights or biases, just a useful aggregator</li>
</ul></li>
<li>Fully connected layers</li>
</ol>
<p><strong>A discrete convolution in 1D</strong></p>
<p>A convolution for two discrete vectors is <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> is given by</p>
<p><span class="math display">\[ z = x * y \rightarrow z_i = \sum_{k=\infty}^{\infty}x[i-k]y[k]\]</span></p>
<p>where it is assumed <span class="math inline">\(x[i] = y[j] = 0\)</span> for all non-index elements of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.</p>
<p>The process of filling these zeros is called <em>zero padding</em>. In addition to utilize the dot prodct it is typically to ‘flip’ the second vector and then dot it with the padded vector.</p>
<p>This gives the effect of “sliding” the smaller of the two vectors across it, and taking a localized weighted sum (dot product) to store in the convolution.</p>
<p>This convolution has two hyperparamter</p>
<ol type="1">
<li>Padding = how much additional zeros do we add to the vector to get</li>
<li>Stride = how far down the vector do we shift to take the next product</li>
</ol>
<p>Aside: This is like if we had a vector length 10 and we had a convolution of length 10, we’d only get a single number with no padding. By adding a bunch of zeros to the end of the vector, we can take local averages of the pixels toward the end of the arrays by themselves (e.g.&nbsp;[0, 1, 2] and [7, 8, 9])</p>
<p>We can use padding and stride lengths to determine the length of the output of the convolution. The three most popular modes of padding are</p>
<ol type="1">
<li>Full = <span class="math inline">\(p = m-1\)</span> this is super largr and starts so the first element <span class="math inline">\(z[0] = x[0]\)</span>. For this reason, it’s rarely used.</li>
<li>Same = <span class="math inline">\(p\)</span> is selected so that the size of the output matches the input.</li>
<li>Valid = <span class="math inline">\(p=0\)</span> ensures that there is no padding at all.</li>
</ol>
<p>Same padding is the most used in CNNs. It’s typically to do a same padding CNNs layer followed by pooling or further convultional layers with higher stride lengths to decrease size for example: https://arxiv.org/abs/1412.6806</p>
<p>To determine the size of the convolutional output layer, we need to understand how many times we shift the filter along the input vector. The fomula is given by</p>
<p><span class="math display">\[ o = \lfloor\frac{n + 2p -m}{s} \rfloor + 1 \]</span></p>
<p>where * n = input size * p = padding size * m = filter size * s = stride length</p>
<p>A naive implementation is given below:</p>
<div id="cell-19" class="cell" data-execution_count="21">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> conv1d(x, y, p<span class="op">=</span><span class="dv">0</span>, s<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    y_rot <span class="op">=</span> np.array(y[::<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    x_pad <span class="op">=</span> np.array(x)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> p <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>        zero_pad <span class="op">=</span> np.zeros(shape<span class="op">=</span>p)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        x_pad <span class="op">=</span> np.concatenate([zero_pad, x_pad, zero_pad])</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    res <span class="op">=</span> []</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">int</span>((<span class="bu">len</span>(x_pad) <span class="op">-</span> <span class="bu">len</span>(y_rot)) <span class="op">+</span> <span class="dv">1</span>), s):</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># range(0, int((len(x_pad) - len(w_rot))) + 1, s)</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>        res.append(np.<span class="bu">sum</span>(x_pad[i : i <span class="op">+</span> y_rot.shape[<span class="dv">0</span>]] <span class="op">*</span> y_rot))</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(res)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-20" class="cell" data-execution_count="22">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">1</span>, <span class="dv">3</span>]</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">2</span>]</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Conv1D Implementation:"</span>, conv1d(x, y, p<span class="op">=</span><span class="dv">2</span>, s<span class="op">=</span><span class="dv">1</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Conv1D Implementation: [ 5. 14. 16. 26. 24. 34. 19. 22.]</code></pre>
</div>
</div>
<div id="cell-21" class="cell" data-execution_count="23">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Numpy results:"</span>, np.convolve(x, y, mode<span class="op">=</span><span class="st">"same"</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Numpy results: [ 5 14 16 26 24 34 19 22]</code></pre>
</div>
</div>
</section>
<section id="performing-2d-convolutions" class="level3">
<h3 class="anchored" data-anchor-id="performing-2d-convolutions">Performing 2D Convolutions</h3>
<p>For a two dimensional convoultion we have</p>
<p><span class="math display">\[Z = X * Y \rightarrow Z[i,j] = \sum_{k_1=-\infty}^{\infty}\sum_{k_2=-\infty}^{\infty}X[i-k_1, j-k_2]Y[k_1, k_2] \]</span></p>
<p>This operation has the effect of passing a filter matrix <span class="math inline">\(Y\)</span> over the matrix <span class="math inline">\(X\)</span> and creating small localized weighted means. This obviously has clear applications in image feature extraction where we want to locally pool pixels in an image.</p>
<div id="cell-25" class="cell" data-execution_count="37">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.signal</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> conv2d(X, Y, p<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">0</span>), s<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>)):</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    Y_rot <span class="op">=</span> np.array(Y)[::<span class="op">-</span><span class="dv">1</span>, ::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    X_orig <span class="op">=</span> np.array(X)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    n1 <span class="op">=</span> X_orig.shape[<span class="dv">0</span>] <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> p[<span class="dv">0</span>]</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    n2 <span class="op">=</span> X_orig.shape[<span class="dv">1</span>] <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> p[<span class="dv">1</span>]</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    X_padded <span class="op">=</span> np.zeros(shape<span class="op">=</span>(n1, n2))</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    X_padded[p[<span class="dv">0</span>] : p[<span class="dv">0</span>] <span class="op">+</span> X_orig.shape[<span class="dv">0</span>], p[<span class="dv">1</span>] : p[<span class="dv">1</span>] <span class="op">+</span> X_orig.shape[<span class="dv">1</span>]] <span class="op">=</span> X_orig</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    res <span class="op">=</span> []</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">int</span>((X_padded.shape[<span class="dv">0</span>] <span class="op">-</span> Y_rot.shape[<span class="dv">0</span>]) <span class="op">/</span> s[<span class="dv">0</span>]) <span class="op">+</span> <span class="dv">1</span>, s[<span class="dv">0</span>]):</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>        res.append([])</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">int</span>((X_padded.shape[<span class="dv">1</span>] <span class="op">-</span> Y_rot.shape[<span class="dv">1</span>]) <span class="op">/</span> s[<span class="dv">1</span>]) <span class="op">+</span> <span class="dv">1</span>, s[<span class="dv">1</span>]):</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>            X_sub <span class="op">=</span> X_padded[i : i <span class="op">+</span> Y_rot.shape[<span class="dv">0</span>], j : j <span class="op">+</span> Y_rot.shape[<span class="dv">1</span>]]</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>            res[<span class="op">-</span><span class="dv">1</span>].append(np.<span class="bu">sum</span>(X_sub <span class="op">*</span> Y_rot))</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(res)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-26" class="cell" data-execution_count="38">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> [[<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">4</span>], [<span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">1</span>, <span class="dv">3</span>], [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">2</span>], [<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">2</span>]]</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> [[<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">3</span>], [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>]]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-27" class="cell" data-execution_count="39">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> conv2d(X, Y, p<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), s<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Conv2d Implentation:</span><span class="ch">\n</span><span class="st">"</span>, x)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Conv2d Implentation:
 [[11. 25. 32. 13.]
 [19. 25. 24. 13.]
 [13. 28. 25. 17.]
 [11. 17. 14.  9.]]</code></pre>
</div>
</div>
<div id="cell-28" class="cell" data-execution_count="41">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"SciPy Implementation:</span><span class="ch">\n</span><span class="st">"</span>, scipy.signal.convolve2d(X, Y, mode<span class="op">=</span><span class="st">"same"</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>SciPy Implementation:
 [[11 25 32 13]
 [19 25 24 13]
 [13 28 25 17]
 [11 17 14  9]]</code></pre>
</div>
</div>
<p>A few notes on scaling</p>
<ul>
<li>You can do these way faster by using fourier transform tricks</li>
<li>It typical to have a kernel that is much smaller than the input image
<ul>
<li>Typical to have (1, 1), (3, 3) and (5,5) kernels</li>
</ul></li>
</ul>
</section>
<section id="subsampling-layers" class="level3">
<h3 class="anchored" data-anchor-id="subsampling-layers">Subsampling Layers</h3>
<p>There are two types of pooling layers in CNNs which decrease the size of the feature set and reduces the dependence on one pixel in the image encouraging generalizability.</p>
<ol type="1">
<li>max pooling = take the max in pixel neighborhood</li>
<li>mean pooling = take the mean in pixel neighborhood</li>
</ol>
<p>And the neighborhod size (or pooling size) determines the size of the neighborhood.</p>
<p>Max pooling is great for local heterogenity and robust to noise in the input data. Mean pooling</p>
<p>These can be used to reduce feature size OR another convolution layer with higher stride lengths.</p>
<p>To understand the differences between these two aproaches see here: https://arxiv.org/abs/1412.6806</p>
</section>
<section id="implementing-a-cnn" class="level3">
<h3 class="anchored" data-anchor-id="implementing-a-cnn">Implementing a CNN</h3>
<p>They key difference between tabular ANNs and CNNs is how we process the inputs:</p>
<ul>
<li>ANN: <span class="math inline">\(z_1 = Wx + b\)</span> where <span class="math inline">\(x\)</span> is a vectorized input of pixels</li>
<li>CNN: <span class="math inline">\(z_1 = W*X + b\)</span> where <span class="math inline">\(X\)</span> is a matrix of pixels passed via a convolution</li>
</ul>
<p>Since pictures could be represented in multiple colors we need to understand how to process color channels.</p>
<p>Each picture will be represented by a <span class="math inline">\(n_1 \times n_2 \times c\)</span> tensor where <span class="math inline">\(c\)</span> is the number of color channels.</p>
<div id="cell-37" class="cell" data-execution_count="44">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reading in images</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.io <span class="im">import</span> read_image</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> read_image(<span class="st">"./figures/other/cat.png"</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Image shape:"</span>, img.shape)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of channels:"</span>, img.shape[<span class="dv">0</span>])</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Image data type:"</span>, img.dtype)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Image shape: torch.Size([4, 360, 360])
Number of channels: 4
Image data type: torch.uint8</code></pre>
</div>
</div>
<div id="cell-38" class="cell" data-execution_count="45">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(img[:, <span class="dv">100</span>:<span class="dv">102</span>, <span class="dv">100</span>:<span class="dv">102</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[[140, 132],
         [129, 135]],

        [[140, 132],
         [129, 135]],

        [[140, 132],
         [129, 135]],

        [[  0,   0],
         [  0,   0]]], dtype=torch.uint8)</code></pre>
</div>
</div>
<p>Given this how can we incorperate each channel into our convolution? We do it for each channel then add them together.</p>
<p>Suppose each channel has it owns kernel matrix <span class="math inline">\(W[::c]\)</span> then the pre-activation inputs are given by</p>
<p><span class="math display">\[Z^{(conv)} = \sum_{c=1}^CW[:,:,c] * X[:, :, c] \]</span> <span class="math display">\[Z = Z^{(conv)} + b\]</span> <span class="math display">\[A = \sigma(Z)\]</span></p>
<p>Where this last matrix <span class="math inline">\(A\)</span> is called our feature map.</p>
<p>It is typical for a CNN layer to have more than one feature map which is specificed by passing different kernels over each channel. That is:</p>
<p><span class="math display">\[Z^{(conv)}[:,:,k] = \sum_{c=1}^CW[:,:,c, k] * X[:, :, c]\]</span> <span class="math display">\[Z[:,:,k] = Z^{(conv)}[:,:,k] + b[k]\]</span> <span class="math display">\[A[:,:,k] = \sigma(Z[:,:,k)\]</span></p>
<p>which supplies us with <span class="math inline">\(K\)</span> different feature maps which can be used in subsequent layers for learning.</p>
<p>So the steps are as follows:</p>
<ol type="1">
<li>For each kernel <span class="math inline">\(K\)</span>, convolve over each channel <span class="math inline">\(C\)</span> and add them up.</li>
<li>Do this for each kernel which provides <span class="math inline">\(K\)</span> new elements to work with.</li>
<li>Perform max pooling with also results in <span class="math inline">\(K\)</span> elements but of possible smaller dimesion</li>
</ol>
<p>Aside: This was not super well explained. The point is that you can create individual feature maps by passing different kerels over each channel. Aggregating those feature maps serves as useful inputs for down the network. Morever, the network can learn what these kernels should be to maximize impact of these feature maps.</p>
<p><strong>Regularization</strong></p>
<p>These models truly have an insane number of weights so learning how to perform regularization seems really important.</p>
<p>We’ll disuss <span class="math inline">\(\ell_2\)</span> regularization by regularizating the parameters in each layer and <em>dropout</em> which randomly drops nodes from the network during training to ensure no one section of the network becomes too important and removes ReLu dead neurons.</p>
<div id="cell-46" class="cell" data-execution_count="46">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ell_2 regularization</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>loss_func <span class="op">=</span> nn.BCELoss()</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> loss_func(torch.tensor([<span class="fl">0.9</span>]), torch.tensor([<span class="fl">1.0</span>]))</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>l2_lambda <span class="op">=</span> <span class="fl">0.001</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>conv_layer <span class="op">=</span> nn.Conv2d(in_channels<span class="op">=</span><span class="dv">3</span>, out_channels<span class="op">=</span><span class="dv">5</span>, kernel_size<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>l2_penalty <span class="op">=</span> l2_lambda <span class="op">*</span> <span class="bu">sum</span>([(p<span class="op">**</span><span class="dv">2</span>).<span class="bu">sum</span>() <span class="cf">for</span> p <span class="kw">in</span> conv_layer.parameters()])</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>loss_with_penalty <span class="op">=</span> loss <span class="op">+</span> l2_penalty</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>linear_layer <span class="op">=</span> nn.Linear(<span class="dv">10</span>, <span class="dv">16</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>l2_penalty <span class="op">=</span> l2_lambda <span class="op">*</span> <span class="bu">sum</span>([(p<span class="op">**</span><span class="dv">2</span>).<span class="bu">sum</span>() <span class="cf">for</span> p <span class="kw">in</span> linear_layer.parameters()])</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>loss_with_penalty <span class="op">=</span> loss <span class="op">+</span> l2_penalty</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>While we can use this <a href="https://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf">droput</a> remains the most important regularization method.</p>
<p>During training, we will randomly drop neurons with a certain probability <span class="math inline">\(p\)</span> (commonly set to <span class="math inline">\(p=0.5\)</span>). This forces the network to learn <em>redudant information in the training data</em> increasing the model’s robustness.</p>
<p>Implicitly this technique is performing ensemble learning as it learns different parts of feature-label relationship during each epoch.</p>
<p>Aside: There is a very out of place discussion on the difference between categorial and binary classification and the differ ways to implement in in PyTorch which we’ll now code up.</p>
<div id="cell-50" class="cell" data-execution_count="48">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Binary Cross Entropy</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> torch.tensor([<span class="fl">0.8</span>])</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> torch.sigmoid(logits)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>])</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>bce_loss_fn <span class="op">=</span> nn.BCELoss()</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>bce_logits_loss_fn <span class="op">=</span> nn.BCEWithLogitsLoss()</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"BCE (with Probs): </span><span class="sc">{</span>bce_loss_fn(probs, target)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"BCE (with Logits): </span><span class="sc">{</span>bce_logits_loss_fn(logits, target)<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>BCE (with Probs): 0.3711
BCE (with Logits): 0.3711</code></pre>
</div>
</div>
<div id="cell-51" class="cell" data-execution_count="53">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Categorical Cross Entropy</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> torch.tensor([[<span class="fl">1.5</span>, <span class="fl">0.8</span>, <span class="fl">2.1</span>]])</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> torch.softmax(logits, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> torch.tensor([<span class="dv">2</span>])</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>cce_loss_fn <span class="op">=</span> nn.NLLLoss()</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>cce_logits_loss_fn <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"CCE (with Probs): </span><span class="sc">{</span>cce_loss_fn(torch.log(probs), target)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"CCE (with Logits): </span><span class="sc">{</span>cce_logits_loss_fn(logits, target)<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>CCE (with Probs): 0.5996
CCE (with Logits): 0.5996</code></pre>
</div>
</div>
</section>
<section id="implementing-a-cnn-with-pytorch" class="level3">
<h3 class="anchored" data-anchor-id="implementing-a-cnn-with-pytorch">Implementing a CNN with PyTorch</h3>
<p>We will work with greyscale images and process <em>batchsize</em> images at a time. Therefore our input tensor will be <span class="math inline">\(batchsize 28 \times 28 \times 1\)</span> in size.</p>
<p>From here we can summarize the CNN architecture as follows:</p>
<ol type="1">
<li>We will put the images through two CNN layers with a kernel size of <span class="math inline">\(5\times 5\)</span>.</li>
<li>We will extract 32 feature maps from the first layer and 64 from teh second</li>
<li>We proces each CNN layer with a max pooling layer of size <span class="math inline">\(2\times 2\)</span>.</li>
<li>We then flatten these and pass it through two fully connected layers to a multi-output head.</li>
</ol>
<p>The dimensions can be summarized as follows:</p>
<ul>
<li>Input: <span class="math inline">\([bs \times 28\times 28 \times 1]\)</span></li>
<li>Conv1: <span class="math inline">\([bs \times 28 \times 28 \times 32]\)</span></li>
<li>Pooling1: <span class="math inline">\([bs \times 14 \times 14 \times 32]\)</span></li>
<li>Conv2: <span class="math inline">\([bs \times 14 \times 14 \times 64]\)</span></li>
<li>Pooling2: <span class="math inline">\([bs \times 7 \times 7 \times 64]\)</span></li>
<li>FC1: <span class="math inline">\([bs \times 1024]\)</span></li>
<li>FC2 and softmax: <span class="math inline">\([bs \times 10]\)</span></li>
</ul>
<div id="cell-55" class="cell" data-execution_count="70">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load and preprocess MNIST</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Subset</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>image_path <span class="op">=</span> <span class="st">"./figures/"</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([transforms.ToTensor()])</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>mnist_dataset <span class="op">=</span> torchvision.datasets.MNIST(</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    root<span class="op">=</span>image_path, train<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform, download<span class="op">=</span><span class="va">False</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>mnist_valid_dataset <span class="op">=</span> Subset(mnist_dataset, torch.arange(<span class="dv">10_000</span>))</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>mnist_train_dataset <span class="op">=</span> Subset(mnist_dataset, torch.arange(<span class="dv">10_000</span>, <span class="bu">len</span>(mnist_dataset)))</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>mnist_test_dataset <span class="op">=</span> torchvision.datasets.MNIST(</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>    root<span class="op">=</span>image_path, train<span class="op">=</span><span class="va">False</span>, transform<span class="op">=</span>transform, download<span class="op">=</span><span class="va">False</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-56" class="cell" data-execution_count="71">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create data loader to batch in 64 images at a time</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">1</span>)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>train_d1 <span class="op">=</span> DataLoader(mnist_train_dataset, batch_size, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>valid_d1 <span class="op">=</span> DataLoader(mnist_valid_dataset, batch_size, shuffle<span class="op">=</span><span class="va">False</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>For implementation we will use the <em>nn.Sequential</em> module to stack different layers. Each layer will come as a subclass from the base <em>nn.Module</em> class</p>
<ul>
<li><em>nn.Conv2d</em> = convolutional layer</li>
<li><em>nn.maxPool2d</em> = max pooling layer</li>
<li><em>nn.AvgPool2d</em> = average pooling layer</li>
<li><em>nn.Dropout</em> = dropout layer</li>
</ul>
<div id="cell-58" class="cell" data-execution_count="72">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> nn.Sequential()</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co"># add first convolutional layer</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>model.add_module(</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"conv1"</span>,</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    nn.Conv2d(</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>        in_channels<span class="op">=</span><span class="dv">1</span>,  <span class="co"># number of channels incoming</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>        out_channels<span class="op">=</span><span class="dv">32</span>,  <span class="co"># number of feature maps to extract</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>        kernel_size<span class="op">=</span><span class="dv">5</span>,  <span class="co"># size of window</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>        padding<span class="op">=</span><span class="dv">2</span>,  <span class="co"># padding of image</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>model.add_module(<span class="st">"relu1"</span>, nn.ReLU())</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>model.add_module(<span class="st">"pool1"</span>, nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">2</span>))</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="co"># add second convolutional layer</span></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>model.add_module(</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">"conv2"</span>,</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>    nn.Conv2d(</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>        in_channels<span class="op">=</span><span class="dv">32</span>,  <span class="co"># number of channels incoming</span></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>        out_channels<span class="op">=</span><span class="dv">64</span>,  <span class="co"># number of feature maps to extract</span></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>        kernel_size<span class="op">=</span><span class="dv">5</span>,  <span class="co"># size of window</span></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>        padding<span class="op">=</span><span class="dv">2</span>,  <span class="co"># padding of image</span></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>model.add_module(<span class="st">"relu2"</span>, nn.ReLU())</span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>model.add_module(<span class="st">"pool2"</span>, nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">2</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-59" class="cell" data-execution_count="73">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We can compute the output size of the network at this stage by computing:</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.ones((<span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>))</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>model(x).shape</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="co"># which gives 4 images, 64 feature maps, of size 7x7</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="73">
<pre><code>torch.Size([4, 64, 7, 7])</code></pre>
</div>
</div>
<div id="cell-60" class="cell" data-execution_count="74">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># now flatten and pass through fully connected layers</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>model.add_module(<span class="st">"flatten"</span>, nn.Flatten())</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>model(x).shape</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="74">
<pre><code>torch.Size([4, 3136])</code></pre>
</div>
</div>
<div id="cell-61" class="cell" data-execution_count="75">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>model.add_module(<span class="st">"fc1"</span>, nn.Linear(<span class="dv">3136</span>, <span class="dv">1024</span>))</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>model.add_module(<span class="st">"relu3"</span>, nn.ReLU())</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>model.add_module(<span class="st">"dropout"</span>, nn.Dropout(p<span class="op">=</span><span class="fl">0.5</span>))</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>model.add_module(<span class="st">"fc2"</span>, nn.Linear(<span class="dv">1024</span>, <span class="dv">10</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-62" class="cell" data-execution_count="76">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create optimizer and loss</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-63" class="cell" data-execution_count="83">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># training loop</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(model, num_epochs, train_d1, valid_d1):</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    loss_hist_train <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> num_epochs</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    accuracy_hist_train <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> num_epochs</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    loss_hist_valid <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> num_epochs</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    accuracy_hist_valid <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> num_epochs</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>        model.train()  <span class="co"># set to train mode because of dropout!</span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> x_batch, y_batch <span class="kw">in</span> train_d1:</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>            <span class="co"># get predictions</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>            pred <span class="op">=</span> model(x_batch)</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>            <span class="co"># compute loss and back propogate</span></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(pred, y_batch)</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>            <span class="co"># optimize</span></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>            <span class="co"># log</span></span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>            loss_hist_train[epoch] <span class="op">+=</span> loss.item() <span class="op">*</span> y_batch.size(<span class="dv">0</span>)</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>            is_correct <span class="op">=</span> (torch.argmax(pred, dim<span class="op">=</span><span class="dv">1</span>) <span class="op">==</span> y_batch).<span class="bu">float</span>()</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>            accuracy_hist_train[epoch] <span class="op">+=</span> is_correct.<span class="bu">sum</span>()</span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>        loss_hist_train[epoch] <span class="op">/=</span> <span class="bu">len</span>(train_d1.dataset)</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>        accuracy_hist_train[epoch] <span class="op">/=</span> <span class="bu">len</span>(train_d1.dataset)</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> x_batch, y_batch <span class="kw">in</span> valid_d1:</span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>                pred <span class="op">=</span> model(x_batch)</span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a>                loss <span class="op">=</span> loss_fn(pred, y_batch)</span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a>                loss_hist_valid[epoch] <span class="op">+=</span> loss.item() <span class="op">*</span> y_batch.size(<span class="dv">0</span>)</span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a>                is_correct <span class="op">=</span> (torch.argmax(pred, dim<span class="op">=</span><span class="dv">1</span>) <span class="op">==</span> y_batch).<span class="bu">float</span>()</span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a>                accuracy_hist_valid[epoch] <span class="op">+=</span> is_correct.<span class="bu">sum</span>()</span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a>        loss_hist_valid[epoch] <span class="op">/=</span> <span class="bu">len</span>(valid_d1.dataset)</span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a>        accuracy_hist_valid[epoch] <span class="op">/=</span> <span class="bu">len</span>(valid_d1.dataset)</span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-41"><a href="#cb30-41" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"""</span></span>
<span id="cb30-42"><a href="#cb30-42" aria-hidden="true" tabindex="-1"></a><span class="ss">              Epoch </span><span class="sc">{</span>epoch <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss"> </span></span>
<span id="cb30-43"><a href="#cb30-43" aria-hidden="true" tabindex="-1"></a><span class="ss">              Train accuracy: </span><span class="sc">{</span>accuracy_hist_train[epoch]<span class="sc">:.4f}</span><span class="ss"> </span></span>
<span id="cb30-44"><a href="#cb30-44" aria-hidden="true" tabindex="-1"></a><span class="ss">              Validation accuracy </span><span class="sc">{</span>accuracy_hist_valid[epoch]<span class="sc">:.4f}</span><span class="ss"> </span></span>
<span id="cb30-45"><a href="#cb30-45" aria-hidden="true" tabindex="-1"></a><span class="ss">              """</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-64" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">1</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>hist <span class="op">=</span> train(model, num_epochs, train_d1, valid_d1)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-65" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>x_arr <span class="op">=</span> np.arange(<span class="bu">len</span>(hist[<span class="dv">0</span>])) <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>ax.plot(x_arr, hist[<span class="dv">0</span>],  <span class="st">'-o'</span>, label<span class="op">=</span><span class="st">'Train loss'</span>)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>ax.plot(x_arr, hist[<span class="dv">1</span>],  <span class="st">'--&lt;'</span>, label<span class="op">=</span><span class="st">'Validation loss'</span>)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>ax.legend(fontsize<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>ax.plot(x_arr, hist[<span class="dv">2</span>],  <span class="st">'-o'</span>, label<span class="op">=</span><span class="st">'Train acc.'</span>) <span class="op">&gt;&gt;&gt;</span> ax.plot(x_arr, hist[<span class="dv">3</span>],  <span class="st">'--&lt;'</span>,</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>                                                               label<span class="op">=</span><span class="st">'Validation acc.'</span>)</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>ax.legend(fontsize<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Epoch'</span>, size<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Accuracy'</span>, size<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("dravesb\.github\.io");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>