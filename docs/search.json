[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "My name is Benjamin Draves and I’m a Staff Applied Scientist at Uber in NYC. I work on building ML systems to grow Uber’s consumer and earner businesses. This includes Recommendation Systems, Causal ML targeting system, and timing optimization systems.\nBefore Uber, I received my Ph.D. in Statistics from Boston University and wrote my dissertation on spectral embedding methods for multiple network data and continue to study network science and matrix analysis methods. Outside of work, I enjoy distance running, soccer, reading, and exploring NYC."
  },
  {
    "objectID": "about.html#data-science-topics-that-excite-me",
    "href": "about.html#data-science-topics-that-excite-me",
    "title": "About Me",
    "section": "Data Science Topics that Excite Me",
    "text": "Data Science Topics that Excite Me\n\nRecommendation Systems\nCausal Machine Learning\nGraph Embeddings and Network Inference\nStatistical Pedagogy"
  },
  {
    "objectID": "about.html#experiences-education",
    "href": "about.html#experiences-education",
    "title": "About Me",
    "section": "Experiences & Education",
    "text": "Experiences & Education\n\n[2022-Present] Applied Scientist @ Uber\n[2017-2022] Ph.D. | M.A. in Stat @ Boston University\n[2014-2017] B.S. in Math @ Lafayette College"
  },
  {
    "objectID": "about.html#contact-information",
    "href": "about.html#contact-information",
    "title": "About Me",
    "section": "Contact Information",
    "text": "Contact Information\nIf you wish to discuss what I’m working on please feel free to email me at benjamin.draves@gmail.com."
  },
  {
    "objectID": "blog/working_on/working_on_scroll.html",
    "href": "blog/working_on/working_on_scroll.html",
    "title": "Working On",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "blog/reading/reading_scroll.html",
    "href": "blog/reading/reading_scroll.html",
    "title": "Reading",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nNov 11, 2024\n\n\nML with PyTorch & Scikit-Learn: Chapter 11\n\n\nBenjamin Draves\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to Central Tendencies",
    "section": "",
    "text": "Welcome to my blog - Central Tendencies. My name is Benjamin Draves and I’m a Staff Applied Scientist at Uber in NYC. I’m interested in recommendation systems, causal machine learning, and statistics and write about these topics. The purpose of Central Tendencies is to share what I am reading about and working on in hope of starting conversations with fellow data scientists and statisticians. If you wish to discuss what I’m working on, please feel free to reach out at benjamin.draves@gmail.com."
  },
  {
    "objectID": "blog/thinking_about/thinking_about_scroll.html",
    "href": "blog/thinking_about/thinking_about_scroll.html",
    "title": "Thinking About",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "blog/blog.html",
    "href": "blog/blog.html",
    "title": "Central Tendencies",
    "section": "",
    "text": "Item-Based Collaborative Filtering Recommendation Algorithms\n\n\nPaper notes on item based collaborative filtering - Sarwar et al. 2001\n\n\n\n\n\nDec 1, 2024\n\n\nBenjamin Draves\n\n\n\n\n\n\n\n\n\n\n\n\nGroupLens: An Open Architecture for Collaborative Filtering of Netnews\n\n\nPaper notes on original GroupLens paper introducing Collaborative Filtering for new article recommendation\n\n\n\n\n\nNov 17, 2024\n\n\nBenjamin Draves\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/blog.html#what-i-am-currently",
    "href": "blog/blog.html#what-i-am-currently",
    "title": "Welcome to Central Tendencies",
    "section": "What I am currently…",
    "text": "What I am currently…\n\nReading\nI’m currently working my way through Machine Learning with PyTorch and Scikit-Learn by Raschka, Lui, and Mirjalili to become more comfortable with (i) PyTorch for multi-output models and (ii) GNNs for recommender applications. You can find my notes here.\n\n\n\n\n\n\n\nWorking On"
  },
  {
    "objectID": "blog/blog.html#what-i-was",
    "href": "blog/blog.html#what-i-was",
    "title": "Welcome to Central Tendencies",
    "section": "What I was …",
    "text": "What I was …\n\nReading\n\n\nWorking on"
  },
  {
    "objectID": "blog/reading/reading_posts/ml_with_pytorch_chp11/index.html",
    "href": "blog/reading/reading_posts/ml_with_pytorch_chp11/index.html",
    "title": "ML with PyTorch & Scikit-Learn: Chapter 11",
    "section": "",
    "text": "\\[\n\\mathbb{E}[x] = \\int_{0}^{\\infty} xf(x)dx\n\\]"
  },
  {
    "objectID": "blog/blog.html#what-i-am-currently-working-on",
    "href": "blog/blog.html#what-i-am-currently-working-on",
    "title": "Welcome to Central Tendencies",
    "section": "What I am currently working on…",
    "text": "What I am currently working on…\nI’m currently working my way through Machine Learning with PyTorch and Scikit-Learn by Raschka, Lui, and Mirjalili to become more comfortable with (i) PyTorch for multi-output models and (ii) GNNs for recommender applications. You can find my notes here."
  },
  {
    "objectID": "blog/blog.html#what-i-was-working-on",
    "href": "blog/blog.html#what-i-was-working-on",
    "title": "Welcome to Central Tendencies",
    "section": "What I was working on…",
    "text": "What I was working on…\nYou can find what I was working on here."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Welcome to Central Tendencies",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nNov 11, 2024\n\n\nML with PyTorch & Scikit-Learn: Chapter 11\n\n\nBenjamin Draves\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about copy.html",
    "href": "about copy.html",
    "title": "About Me",
    "section": "",
    "text": "My name is Benjamin Draves and I’m a Senior Applied Scientist at Uber in NYC. I work on building ML recommendation and targeting systems to grow Uber’s consumer and earner businesses.\nBefore Uber, I received my Ph.D. in Statistics from Boston University and wrote my dissertation on spectral embedding methods for multiple network data and continue to study network science and matrix analysis methods. Outside of work, I enjoy distance running, soccer, reading, and exploring NYC."
  },
  {
    "objectID": "about copy.html#data-science-topics-that-excite-me",
    "href": "about copy.html#data-science-topics-that-excite-me",
    "title": "About Me",
    "section": "Data Science Topics that Excite Me",
    "text": "Data Science Topics that Excite Me\n\nRecommendation Systems\nCausal Machine Learning\nGraph Embeddings and Network Inference\nStatistical Pedagogy"
  },
  {
    "objectID": "about copy.html#experiences-education",
    "href": "about copy.html#experiences-education",
    "title": "About Me",
    "section": "Experiences & Education",
    "text": "Experiences & Education\n\n[2022-Present] Applied Scientist @ Uber\n[2017-2022] Ph.D. | M.A. in Stat @ Boston University\n[2014-2017] B.S. in Math @ Lafayette College"
  },
  {
    "objectID": "about copy.html#contact-information",
    "href": "about copy.html#contact-information",
    "title": "About Me",
    "section": "Contact Information",
    "text": "Contact Information\nIf you wish to discuss what I’m working on please feel free to email me at benjamin.draves@gmail.com."
  },
  {
    "objectID": "blog_posts/ml_with_pytorch_chp11/index.html",
    "href": "blog_posts/ml_with_pytorch_chp11/index.html",
    "title": "ML with PyTorch & Scikit-Learn: Chapter 11",
    "section": "",
    "text": "For a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: A line plot on a polar axis\n\n\n\n\n\n\\[\n\\mathbb{E}[x] = \\int_{0}^{\\infty} xf(x)dx\n\\]"
  },
  {
    "objectID": "code/resnick_1994/resnick_1994_demo.html",
    "href": "code/resnick_1994/resnick_1994_demo.html",
    "title": "User Collaborative Filtering",
    "section": "",
    "text": "This script accommodates implementation of user-collaborative filtering from the original GroupLens paper (Resnick et al 1994). See here for a full write up"
  },
  {
    "objectID": "code/resnick_1994/resnick_1994_demo.html#working-with-scipy.sparse",
    "href": "code/resnick_1994/resnick_1994_demo.html#working-with-scipy.sparse",
    "title": "User Collaborative Filtering",
    "section": "Working with scipy.sparse",
    "text": "Working with scipy.sparse\n\nprint(dir(ratings[0]))\n\n['__abs__', '__add__', '__array_priority__', '__bool__', '__class__', '__delattr__', '__dict__', '__dir__', '__div__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__idiv__', '__imul__', '__init__', '__init_subclass__', '__isub__', '__iter__', '__itruediv__', '__le__', '__len__', '__lt__', '__matmul__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__pow__', '__radd__', '__rdiv__', '__reduce__', '__reduce_ex__', '__repr__', '__rmatmul__', '__rmul__', '__round__', '__rsub__', '__rtruediv__', '__setattr__', '__setitem__', '__sizeof__', '__slotnames__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__weakref__', '_add_dense', '_add_sparse', '_arg_min_or_max', '_arg_min_or_max_axis', '_asindices', '_binopt', '_cs_matrix__get_has_canonical_format', '_cs_matrix__get_sorted', '_cs_matrix__set_has_canonical_format', '_cs_matrix__set_sorted', '_deduped_data', '_divide', '_divide_sparse', '_get_arrayXarray', '_get_arrayXint', '_get_arrayXslice', '_get_columnXarray', '_get_dtype', '_get_intXarray', '_get_intXint', '_get_intXslice', '_get_sliceXarray', '_get_sliceXint', '_get_sliceXslice', '_get_submatrix', '_imag', '_inequality', '_insert_many', '_major_index_fancy', '_major_slice', '_maximum_minimum', '_min_or_max', '_min_or_max_axis', '_minor_index_fancy', '_minor_reduce', '_minor_slice', '_mul_multivector', '_mul_scalar', '_mul_sparse_matrix', '_mul_vector', '_prepare_indices', '_process_toarray_args', '_real', '_rsub_dense', '_scalar_binopt', '_set_arrayXarray', '_set_arrayXarray_sparse', '_set_dtype', '_set_intXint', '_set_many', '_set_self', '_setdiag', '_shape', '_sub_dense', '_sub_sparse', '_swap', '_validate_indices', '_with_data', '_zero_many', 'arcsin', 'arcsinh', 'arctan', 'arctanh', 'argmax', 'argmin', 'asformat', 'asfptype', 'astype', 'ceil', 'check_format', 'conj', 'conjugate', 'copy', 'count_nonzero', 'data', 'deg2rad', 'diagonal', 'dot', 'dtype', 'eliminate_zeros', 'expm1', 'floor', 'format', 'getH', 'get_shape', 'getcol', 'getformat', 'getmaxprint', 'getnnz', 'getrow', 'has_canonical_format', 'has_sorted_indices', 'indices', 'indptr', 'log1p', 'max', 'maximum', 'maxprint', 'mean', 'min', 'minimum', 'multiply', 'ndim', 'nnz', 'nonzero', 'power', 'prune', 'rad2deg', 'reshape', 'resize', 'rint', 'set_shape', 'setdiag', 'shape', 'sign', 'sin', 'sinh', 'sort_indices', 'sorted_indices', 'sqrt', 'sum', 'sum_duplicates', 'tan', 'tanh', 'toarray', 'tobsr', 'tocoo', 'tocsc', 'tocsr', 'todense', 'todia', 'todok', 'tolil', 'transpose', 'trunc']\n\n\n\n# shape of first row\nratings[0].shape\n\n(1, 100)\n\n\n\n# Accessing and shape of certain rows and columns\nprint(f'''\n    Row 1            dimension {ratings[0].shape}\n    Row 1 transposed dimension {ratings[0].T.shape}\n    Col 1            dimension {ratings[:, 0].shape}\n    Col 1 transposed dimension {ratings[:, 0].T.shape}\n    '''\n)\n\n\n    Row 1            dimension (1, 100)\n    Row 1 transposed dimension (100, 1)\n    Col 1            dimension (1000, 1)\n    Col 1 transposed dimension (1, 1000)\n    \n\n\n\n# Multiplying rows\nr1_norm2 = ratings[0].dot(ratings[0].T)\nprint(f'Inner product\\n\\t class: {type(r1_norm2)}\\n\\t shape: {r1_norm2.shape}\\n\\t value: {r1_norm2[0, 0]}')\n\nInner product\n     class: &lt;class 'scipy.sparse.csr.csr_matrix'&gt;\n     shape: (1, 1)\n     value: 88.0"
  },
  {
    "objectID": "code/resnick_1994/resnick_1994_demo.html#writting-a-similarity-method",
    "href": "code/resnick_1994/resnick_1994_demo.html#writting-a-similarity-method",
    "title": "User Collaborative Filtering",
    "section": "Writting a Similarity Method",
    "text": "Writting a Similarity Method\n\ndef similarity(u, v, method='cosine'):   \n    '''Return the similarity between entity u and v based on previous ratings\n\n    Args: \n        u (sparse array) - the ratings vector for entity u \n        v (sparse array) - the ratings vector for entity v \n        method (str) - the similarity methods (cosine, adjusted-cosine, pearson)\n\n    Returns: \n        float: A numerical score of the similarity between entities u and v ratings\n    '''\n    # format matrices\n    if method=='cosine':\n        sim = u.dot(v.T)[0,0] / (1e-5 +1.0 * np.sqrt(u.dot(u.T)[0,0] * v.dot(v.T)[0,0]))\n        return(sim)        \n\n    elif method=='pearson':\n        # center vectors \n        u_cen, v_cen = deepcopy(u), deepcopy(v)\n        u_cen.data -= u_cen.data.mean()\n        v_cen.data -= v_cen.data.mean()\n\n        # comptute similarity\n        sim = u_cen.dot(v_cen.T)[0,0] / (1e-5 + 1.0 * np.sqrt(u_cen.dot(u_cen.T)[0,0] * v_cen.dot(v_cen.T)[0,0]))\n        return(sim)\n\n    else: \n        return(\"Please use method = {'cosine', 'pearson'}\")\n\n\n# Examples! \nind1, ind2 = 0, 3\npearson = similarity(ratings[ind1], ratings[ind2], method='pearson')\ncosine = similarity(ratings[ind1], ratings[ind2], method='cosine')\n\nf'The pearson similarity is {np.round(pearson, 2)} and cosine similarity is {np.round(cosine, 2)}.'\n\n'The pearson similarity is -0.14 and cosine similarity is 0.0.'"
  },
  {
    "objectID": "code/resnick_1994/resnick_1994_demo.html#writting-a-hueristic-item-score-imputation",
    "href": "code/resnick_1994/resnick_1994_demo.html#writting-a-hueristic-item-score-imputation",
    "title": "User Collaborative Filtering",
    "section": "Writting a Hueristic Item Score Imputation",
    "text": "Writting a Hueristic Item Score Imputation\n\nx = ratings[0]\n\n\ny = x.nonzero()\n\nprint(x.nonzero())\n\n(array([0, 0, 0, 0], dtype=int32), array([16, 26, 38, 86], dtype=int32))\n\n\n\nnp.\n\narray([0, 0, 0, 0], dtype=int32)\n\n\n\ndef imputed_ratings(id, ratings, method = 'user-to-user', sim_method='cosine'):\n    '''Return the imputed ratings for unobserved-ratings for entity u\n\n    Args: \n        id (int) - id of the entity for the ratings vector to be applied for\n        ratings (sparse matrix) - the ratings matrix to apply CF towards\n        method (str) - the similarity methods (cosine, pearson)\n\n    Returns: \n        cf_ratings (np.array): An np array with imputed estimates of ratings for un-rated articles. \n    '''\n    \n    # find entity and items rated \n    id_vec = ratings[id] if method =='user-to-user' else ratings[:, id]\n    n_users, n_items = ratings.shape \n    entities_rated = id_vec.nonzero()\n    \n    # fetch entity tp entity to entity similarity\n    if method == 'user-to-user':\n        sims = [similarity(id_vec, ratings[i], method=sim_method) for i in range(n_users)]\n    elif method == 'item-to-item': \n        sims = [similarity(id_vec, ratings[:,i], method=sim_method) for i in range(n_items)]\n\n    # compute impute scores for all \n    if method == 'user-to-user': \n        cf_ratings = [ for ]"
  },
  {
    "objectID": "code/resnick_1994/resnick_1994_demo.html#generate-synthetic-data",
    "href": "code/resnick_1994/resnick_1994_demo.html#generate-synthetic-data",
    "title": "User Collaborative Filtering",
    "section": "Generate Synthetic Data",
    "text": "Generate Synthetic Data\n\n### Imports \nimport pandas as pd \nimport numpy as np\nfrom scipy import sparse  \nfrom copy import deepcopy\nimport matplotlib.pyplot as plt \n\n\n# Generate some fake rating data to play with \nn_users = 1_000 # number of users\nn_items = 100 # of items\nratings = sparse.random(n_users, n_items, density=0.10, format='csr', random_state=1985)\nratings.data = np.random.randint(0, 5, size=ratings.data.shape).astype(float)\n\n\n# example rating for a single row\nprint(ratings[0])\n\n  (0, 11)   3.0\n  (0, 16)   4.0\n  (0, 23)   4.0\n  (0, 26)   4.0\n  (0, 34)   1.0\n  (0, 38)   3.0\n  (0, 86)   4.0\n  (0, 89)   2.0\n  (0, 95)   0.0\n  (0, 98)   1.0"
  },
  {
    "objectID": "code/resnick_1994/resnick_1994_demo.html#user-to-user-cf-resnick-1994",
    "href": "code/resnick_1994/resnick_1994_demo.html#user-to-user-cf-resnick-1994",
    "title": "User Collaborative Filtering",
    "section": "User to User CF (Resnick 1994)",
    "text": "User to User CF (Resnick 1994)\n\ndef cf_user_to_user(id, ratings, sim_method='pearson'):\n    '''Return the imputed ratings for unobserved-ratings for entity u\n\n    Args: \n        id (int) - id of the entity for the ratings vector to be applied for\n        ratings (sparse matrix) - the ratings matrix to apply CF towards\n        method (str) - the similarity methods (cosine, pearson)\n\n    Returns: \n        cf_ratings (np.array): An np array with imputed estimates of ratings for un-rated articles. \n    '''\n    # fetch average user rating\n    n_users, n_items = ratings.shape\n    \n    # compute user-to-user similarity\n    sims = np.array([similarity(ratings[id], ratings[user]) for user in range(n_users)])\n    total_sim = np.sum(np.abs(sims))\n\n    # residualize ratings\n    ratings_resid = deepcopy(ratings)\n    ratings_resid.data = ratings_resid.data.astype(float)\n    for user in range(n_users): \n        ratings_resid[user].data -= ratings_resid[user].data.mean()\n    \n    # store previously rated item ratingss\n    cf_ratings = np.full(n_items, np.nan)\n    items_ranked = ratings[id].indices\n    cf_ratings[items_ranked] = ratings[id].data\n\n    # compute average rating for every item not ranked\n    unrated_items = np.setdiff1d(np.arange(n_items), items_ranked)\n    for item in unrated_items: \n        cf_ratings[item] = ratings[id].data.mean() + np.sum(sims * ratings[:,item])/total_sim\n\n    # return ratings\n    return(cf_ratings)\n\n\n\ncf_user_to_user(1, ratings)\n\narray([1.82957415, 1.82499751, 1.85299315, 1.87906179, 1.83613618,\n       1.86996127, 1.83657094, 1.8580771 , 1.94402725, 1.88251208,\n       1.87371842, 1.86202115, 1.8200888 , 1.8981778 , 1.91203758,\n       1.        , 1.86173336, 1.87208495, 1.86493801, 4.        ,\n       1.82864583, 1.86936068, 1.78605192, 1.86331963, 1.82654638,\n       1.92066823, 1.        , 3.        , 1.86705059, 0.        ,\n       1.8646681 , 1.        , 1.86397559, 1.81707945, 1.85286705,\n       1.82227709, 1.83254404, 1.85650547, 0.        , 1.89703854,\n       1.78317043, 1.90312655, 1.89427064, 1.89091876, 1.82548385,\n       1.81282133, 1.82874793, 1.88443935, 1.86564691, 1.84104925,\n       1.        , 1.90751662, 1.85747663, 1.95335813, 0.        ,\n       1.89969457, 1.84086516, 1.84756262, 1.83743379, 2.        ,\n       1.82107291, 1.84559239, 1.90879037, 1.81514726, 1.84039083,\n       1.88859077, 1.90118094, 1.84929746, 1.83720612, 1.86472832,\n       2.        , 1.88060354, 1.90305685, 1.89286469, 1.88215981,\n       1.86623908, 1.87150958, 3.        , 1.87675678, 1.80639099,\n       1.93212828, 1.84710448, 1.85277036, 1.85924812, 4.        ,\n       4.        , 1.90331998, 0.        , 1.85558737, 1.84610447,\n       1.85985853, 1.85272794, 1.81752903, 1.88978615, 1.89229447,\n       1.        , 1.85638961, 1.88321569, 1.86705772, 1.87842497])\n\n\n\nimport numpy as np\nfrom scipy import sparse  \nfrom copy import deepcopy\n\nclass CollabFilter(): \n    def __init__(self): \n        self.n_items = None\n        self.n_users = None\n        self.ratings = None\n        self.cf_ratings = None \n\n    def generate_data(self, n_users, n_items, density=0.1, random_state=1985): \n        \"\"\"\n        Generate a random sparse ratings matrix.\n        \"\"\"\n        # initialize\n        self.n_users = n_users\n        self.n_items = n_items\n\n        # set up random generate \n        rng = np.random.default_rng(random_state)\n        self.ratings = sparse.random(n_users, n_items, density=density, format='csr', random_state=rng)\n        self.ratings.data = rng.integers(1, 6, size=self.ratings.data.shape).astype(float)\n\n    def load_data(self, ratings):\n        \"\"\"\n        Load an external sparse matrix as the ratings matrix.\n        \"\"\"\n        if not isinstance(ratings, scipy.sparse.csr.csr_matrix): \n            raise ValueError(\"Ratings must be a scipy.sparse.csr_matrix.\")\n        \n        self.n_users, self.n_items = ratings.shape\n        self.ratings = ratings \n        \n    @staticmethod \n    def similarity(u, v, method='cosine'):   \n        '''Return the similarity between entity u and v based on previous ratings\n\n        Args: \n            u (sparse array) - the ratings vector for entity u \n            v (sparse array) - the ratings vector for entity v \n            method (str) - the similarity methods (cosine, adjusted-cosine, pearson)\n\n        Returns: \n            float: A numerical score of the similarity between entities u and v ratings\n        '''\n        # format matrices\n        if method=='cosine':\n            # compute l2-norms \n            u_norm = np.sqrt(u.dot(u.T)[0,0])\n            v_norm = np.sqrt(v.dot(v.T)[0,0])\n\n            # return similarity\n            if u_norm == 0.0 or v_norm == 0.0: \n                return(0.0)\n            return u.dot(v.T)[0,0] / (u_norm * v_norm) \n\n        elif method=='pearson':\n            # center vectors \n            u_cen, v_cen = deepcopy(u), deepcopy(v)\n            u_cen.data -= u_cen.data.mean()\n            v_cen.data -= v_cen.data.mean()\n\n            # comptute similarity\n            sim = u_cen.dot(v_cen.T)[0,0] / (1e-5 + 1.0 * np.sqrt(u_cen.dot(u_cen.T)[0,0] * v_cen.dot(v_cen.T)[0,0]))\n            return(sim)\n\n        else: \n            raise ValueError(\"Please use method = {'cosine', 'pearson'}\")\n        \n\n    def collaborative_filter(self, id, ratings, cf_method='user-to-user', sim_method='pearson'):\n        '''Return the imputed ratings for unobserved-ratings for entity u\n\n        Args: \n            id (int) - id of the entity for the ratings vector to be applied for\n            ratings (sparse matrix) - the ratings matrix to apply CF towards\n            method (str) - the similarity methods (cosine, pearson)\n\n        Returns: \n            cf_ratings (np.array): An np array with imputed estimates of ratings for un-rated articles. \n        '''\n        if self.ratings is None:\n            raise ValueError(\"Ratings matrix not initialized. Use generate_data or load_data.\")\n\n        if not (0 &lt;= id &lt; self.n_users):\n            raise ValueError(f\"Invalid user ID. Must be in range [0, {self.n_users - 1}].\")\n\n        # compute user-to-user similarity\n        sims = np.array([self.similarity(self.ratings[id], self.ratings[user]) for user in range(self.n_users)])\n        total_sim = np.sum(np.abs(sims))\n\n        # residualize ratings\n        ratings_resid = deepcopy(self.ratings)\n        ratings_resid.data = ratings_resid.data.astype(float)\n        for user in range(self.n_users): \n            ratings_resid[user].data -= ratings_resid[user].data.mean()\n        \n        # store previously rated item ratings\n        self.cf_ratings = np.full(self.n_items, np.nan)\n        items_ranked = self.ratings[id].indices\n        self.cf_ratings[items_ranked] = self.ratings[id].data\n\n        # compute average rating for every item not ranked\n        unrated_items = np.setdiff1d(np.arange(self.n_items), items_ranked)\n        for item in unrated_items: \n            self.cf_ratings[item] = ratings[id].data.mean() + np.sum(sims * self.ratings[:,item])/total_sim\n\n        return(1)"
  },
  {
    "objectID": "blog/blog_posts/resnick_1994/index.html",
    "href": "blog/blog_posts/resnick_1994/index.html",
    "title": "GroupLens: An Open Architecture for Collaborative Filtering of Netnews",
    "section": "",
    "text": "The GroupLens: An Open Architecture for Collaborative Filtering of Netnews paper was one of the first papers to introduce collaborative filtering for recommendation applications in 1994. The paper focuses on not just the recommendation problem but also how those recommendations are integrated into the Usenet Netnews network, displayed to users, and implications for serving personalized news to users."
  },
  {
    "objectID": "blog/blog_posts/resnick_1994/index.html#collaborative-filtering",
    "href": "blog/blog_posts/resnick_1994/index.html#collaborative-filtering",
    "title": "GroupLens: An Open Architecture for Collaborative Filtering of Netnews",
    "section": "Collaborative Filtering",
    "text": "Collaborative Filtering\nFor each user \\(u\\in\\mathcal{U}\\) and item \\(v\\in\\mathcal{V}\\) we assign the rating \\(u\\) assigns to \\(v\\) as \\(R_{uv}\\). Supposing \\(\\mid\\mathcal{U}\\mid = n\\) and \\(\\mid\\mathcal{V}\\mid = m\\) the ratings matrix \\(\\mathbf{R}\\in\\mathbb{R}^{n\\times m}\\) with\n\\[\n\\mathbf{R} = \\begin{bmatrix}\nR_{11} & \\dots & R_{1m}\\\\\nR_{21} & \\dots & R_{2m}\\\\\n\\vdots & \\ddots & \\vdots\\\\\nR_{n1} & \\dots & R_{nm}\n\\end{bmatrix}\n\\]\nNow, several entries in \\(\\mathbf{R}\\) will be missing as not every (user, item) pair will be rated.\nThe authors impute this missing scores based on the hueristic that “people who agreed in the past are likely to agree again.” To impute the missing rating \\(R_{uv}\\) they follow:\n\nUnderstand how similar user \\(u\\) is to all other users.\nScore the item \\(v\\) based on previous ratings of other users on \\(v\\) taking into account how similar the user is to \\(u\\).\n\nThis manifests in the scoring equation \\[\n\\hat{R}_{uv} = \\bar{R_u} + \\frac{\\sum_{s\\neq u} \\text{sim}(u, s)(R_{iv} - \\bar{R}_i)}{\\sum_{s\\neq u} |\\text{sim}(u, s)|}\n\\]\nHere, we first residualize all ratings relative to the user’s average rating. This removes any user-level bias or different interpretations of the rating scale. From here, we simply take a weighted sum of the ratings on item \\(v\\) for each user, weighted by the similarity between the user providing that rating \\(i\\) and user \\(u\\). The authors propose to model user-to-user similarity using simple correlation scores:\n\\[\n\\text{sim}(u, s) = \\frac{\\sum_{j=1}^m(R_{uj} - \\bar{R}_{u})(R_{sj} - \\bar{R}_{s})}{\\sqrt{\\sum_{j=1}^m(R_{uj} - \\bar{R}_{u})^2}\\sqrt{\\sum_{j=1}^m(R_{sj} - \\bar{R}_{s})^2}} \\in [-1, 1]\n\\]\nIn both of these equations, if \\(R_{uv}\\) is unobserved, then that term in the summand is removed. Therefore, if two users \\((u, s)\\) do not score any of the same items, their similarity is set to zero and user \\(s\\) ratings do not impact the rating estimates for user \\(u\\).\nThis approach is typically referred to user-collaborative filtering (since we measure user-to-user similarity) in modern applications and similar approaches for item-collaborative filtering"
  },
  {
    "objectID": "blog/blog_posts/resnick_1994/index.html#collaborative-filtering---extensions",
    "href": "blog/blog_posts/resnick_1994/index.html#collaborative-filtering---extensions",
    "title": "GroupLens: An Open Architecture for Collaborative Filtering of Netnews",
    "section": "Collaborative Filtering - Extensions",
    "text": "Collaborative Filtering - Extensions\nThe authors point out a number of limitations with this approach which are approached with newer methodologies but crucially they discuss:\n\nThis method does not utilize implicit feedback\nThis method does not utilize features of the users or items\nSimilarity scoring across all users will not scale"
  },
  {
    "objectID": "code/example/example.html",
    "href": "code/example/example.html",
    "title": "Central Tendencies",
    "section": "",
    "text": "def add(a, b): \n    return a + b"
  },
  {
    "objectID": "blog/blog_posts/sarwar_2001/index.html",
    "href": "blog/blog_posts/sarwar_2001/index.html",
    "title": "Item-Based Collaborative Filtering Recommendation Algorithms",
    "section": "",
    "text": "Sarwar et al.’s 2001 paper on Item-Based Collaborative Filtering is one of the first papers from the GroupLens group on estimating user-item ratings utilizing item-to-item similarities. This paper discusses an item based similarity rating scheme and much of the computational benefits one can gain from utilizing the item-based approach and a model rating estimation framework. Moreover, the authors provide thorough experiments which address the impact of data sparsity, neighborhood size, and similarity measures on the performance of this algorithm."
  },
  {
    "objectID": "blog/blog_posts/sarwar_2001/index.html#item-based-collaborative-filtering",
    "href": "blog/blog_posts/sarwar_2001/index.html#item-based-collaborative-filtering",
    "title": "Item-Based Collaborative Filtering Recommendation Algorithms",
    "section": "Item-Based Collaborative Filtering",
    "text": "Item-Based Collaborative Filtering\nSimilar to user-to-user based collaborative filtering, ratings can be estimated using either (i) a memory based score utilizing weighted sums of observed ratings or (ii) a model based score using rules learned from the observed ratings data. For the memory based approach, ratings are estimated as:\n\\[\n\\hat{R}_{us} = \\frac{\\sum_{t\\in N(s)}\\text{sim}(s, t)R_{ut}}{\\sum_{t\\in N(s)}\\mid\\text{sim}(s, t)\\mid}\n\\]\nwhere the neighborhood \\(N(s)\\) is the set of all items that share a co-rater (e.g. someone who rated both item \\(s\\) and \\(t\\)). Notice here we do not need to mean center user \\(u\\)’s ratings as we only utilize their ratings in this computation. Moreover, we can pre-compute the neighborhood \\(N(s)\\) and the item-to-item similarities offline improving performance.\nIn addition to this scoring methodology, the authors introduce a regression-based model approach. They utilizing the same scoring function above by utilize the smoothed scores \\(\\tilde{R}_{ut}\\) by first regressing the item vectors \\(R_{\\cdot, t}\\) onto \\(R_{\\cdot, s}\\). (Candidly, I found this section very hard to follow. I think Aggarwal’s Section 2.6 connects these ideas more clearly.)"
  },
  {
    "objectID": "blog/blog_posts/sarwar_2001/index.html#measuring-item-similarity",
    "href": "blog/blog_posts/sarwar_2001/index.html#measuring-item-similarity",
    "title": "Item-Based Collaborative Filtering Recommendation Algorithms",
    "section": "Measuring Item Similarity",
    "text": "Measuring Item Similarity\nMeasuring item-to-item similarity is the key to solving the collaborative filtering problem. The authors introduce three methods which are still popular today. For ease of notation, let \\(r_s\\in\\mathbb{R}^N\\) denote the ratings vector for item \\(s\\). Then the three methods are given by\n\nCosine similarity: \\[\n  \\text{sim}(s, t) = \\frac{r_s^Tr_t}{\\|r_s\\|_2\\|r_t\\|_2}\n  \\]\nAdjusted-cosine similarity: \\[\n  \\text{sim}(s, t) = \\frac{\\sum_{i=1}^n(R_{is} - \\bar{R}_i)(R_{it} - \\bar{R}_i)}{\\sqrt{\\sum_{i=1}^n(R_{is} - \\bar{R}_i)^2}\\sqrt{\\sum_{i=1}^n(R_{it} - \\bar{R}_i)^2}}\n  \\]\nCorrelation similarity: \\[\n  \\text{sim}(s, t) = \\frac{\\sum_{i=1}^n(R_{is} - \\bar{R}_s)(R_{it} - \\bar{R}_t)}{\\sqrt{\\sum_{i=1}^n(R_{is} - \\bar{R}_s)^2}\\sqrt{\\sum_{i=1}^n(R_{it} - \\bar{R}_t)^2}}\n  \\]\n\nThe unifying piece of each of these similarity methods is the cosine similarity operator. The only thing that changes between these methods is which matrix of ratings it acts on.\nFor instance, taking \\(\\ell_2\\)-normalized dot products of column vectors in \\(R\\) gives the cosine similarity. The same operation on the mean-centered rows gives the adjusted cosine similarity and mean-center columns give the correlation similarity.\nTherefore, I think it’s better to think about each of these similarity measures as performing the same operation (i.e. cosine-similarity between column vectors) just on difference matrices:\n\nCosine similarity: \\(R\\)\nAdjusted-cosine similarity: \\(R - (R\\mathbf{1}_m\\mathbf{1}_m^T)/m\\)\nCorrelation similarity: \\(R - (\\mathbf{1}_n\\mathbf{1}_n^TR)/n\\)\n\nI’m ignoring the fact that some ratings here are not-present and writing \\(1/m\\) and \\(1/n\\) for normalizing constants, but the spirit holds."
  },
  {
    "objectID": "blog/blog_posts/sarwar_2001/index.html#compute-performance",
    "href": "blog/blog_posts/sarwar_2001/index.html#compute-performance",
    "title": "Item-Based Collaborative Filtering Recommendation Algorithms",
    "section": "Compute Performance",
    "text": "Compute Performance\nThe authors spend most of their attention not on measuring the differences between model based and memory based approaches (they do concede that model based approaches are more scalable in the long run) and more so on separating the neighborhood construction and the ratings estimation in offline and online batches, respectively.\nThey authors recommend that instead of computing the full neighborhood, only the top \\(k\\) most similar items are retained (stochastic gradient descent vibes). They call this parameter \\(k\\) the model size or the neighborhood size.\nThe authors cary out a number of experimental examples and show that\n\nThe memory based method outperforms the regression based method and demonstrate overfitting when the neighborhood size gets too large: \nThe algorithm only needs the most similar items in an item’s neighborhood to estimate ratings accurately. In the paper they state “… we were within 96% and 98.3% of the full item-item scheme’s accuracy using only 1.3% and 3.0% of the items, respectively!” \n\nThese findings aren’t too surprising but do garner insights into ways to speed up this algorithm in online inference settings and again demonstrates bias-variance tradeoffs in offline model training."
  },
  {
    "objectID": "blog/blog_posts/sarwar_2001/index.html#recommendation-performance",
    "href": "blog/blog_posts/sarwar_2001/index.html#recommendation-performance",
    "title": "Item-Based Collaborative Filtering Recommendation Algorithms",
    "section": "Recommendation Performance",
    "text": "Recommendation Performance\nThe paper mostly focused on assessing the algorithms performance with respect to MAE utilizing a train-test split. For collaborative filtering approaches, I also find this a bit concerning because severing the user-item bipartite graph impacts training of all collaborative filtering methods. Nonetheless, the authors carry out a classic training-testing split, and cross validate on the training set to tune the item-to-item collaborative filtering methods. Their key findings include\n\nAdjusted-cosine similarity out performs other similarity methods\nAfter tuning, item-to-item give similar, if not preferable, results compared to user-to-user methods for certain combinations of data sparsity and neighborhood sizes.\n\nIn aggregate, I think these results validate the performance of this method as a valid and interesting alternative to user-to-user collaborative filtering."
  },
  {
    "objectID": "notes/book-notes/rashka-2022/chp12.html",
    "href": "notes/book-notes/rashka-2022/chp12.html",
    "title": "Chapter 12: Parallelizing Neural Network Training with PyTorch",
    "section": "",
    "text": "Training Performance, Hardware, and PyTorch\nTensors\nDataset, TensorDataset, and DataLoader\nBuilding a Nueral Network with PyTorch\nChoice of Activation Functions"
  },
  {
    "objectID": "notes/book-notes/rashka-2022/chp13.html",
    "href": "notes/book-notes/rashka-2022/chp13.html",
    "title": "Chapter 13: Going Deeper - The Mechanics of PyTorch",
    "section": "",
    "text": "Sections:\n\nPyTorch Computational Graphs\nTensor Objects for Model Updates\nComputing Gradients via Autograd\nSimplifying Implementations\nProjects\n\nPredicing Fuel Efficiency\nClassifying MNIST\n\nPyTorch Lightning\n\n\n\nPyTorch Computational Graphs\nA few key features of why PyTorch is the go-to development tool include: 1. Open source with private support (Facebook) 2. Dynamic computational graphs will full visibility into the code 3. GPU integration 4. Mobile deployment for production use cases\n\nPyTorch performs its computations based on DAGs.\nIt derives relationships between tensors based on these DAGs.\n\nLet’s say we have a rank 0 tensors \\(a, b, c\\) and we want to compute \\(z = 2(a-b) + c\\). Then we can write this as a DAG\n\na, b –&gt; r1 = a - b\nr1 –&gt; r2 = 2r1\nr1, c –&gt; z = r2 + c\n\nWe an implement this DAG directly in Torch:\n\nimport torch\n\n\ndef compute_z(a, b, c):\n    r1 = torch.sub(a, b)\n    r2 = torch.mul(r1, 2)\n    z = torch.add(r2, c)\n    return z\n\nWe can impute scalar inputs to compute_z\n\nprint(\"scalar inputs:\", compute_z(torch.tensor(1), torch.tensor(2), torch.tensor(3)))\n\nscalar inputs: tensor(1)\n\n\nWe can also inpute parameters of higher order and torch will return tensors of that rank.\n\nprint(\n    \"rank 1 inputs:\", compute_z(torch.tensor([1]), torch.tensor([2]), torch.tensor([3]))\n)\nprint(\n    \"rank 2 inputs:\",\n    compute_z(torch.tensor([[1]]), torch.tensor([[2]]), torch.tensor([[3]])),\n)\n\nrank 1 inputs: tensor([1])\nrank 2 inputs: tensor([[1]])\n\n\n\n\nTensor Objects for Model Updates\nIn PyTroch there is a special tensor that is reserved for updating gradients which need to be stored for updating model parameters"
  },
  {
    "objectID": "notes/study_guides/rashka-2022/pytorch_basics.html",
    "href": "notes/study_guides/rashka-2022/pytorch_basics.html",
    "title": "PyTorch Basics",
    "section": "",
    "text": "Creating and manipulating tensors\nDataset, Dataloader, TensorDataset\nBuilding a lightweight example [save this for chp 13?]\n\nChp 13: Going Deeper - mechanics of PyTorch\n\nComputational Graphs and Auograd\nModules: Torch.nn: nn.Sequenetial, nn.Module\nCustom Layers using nn.Module\n\n\nTensors\n\nPytorch is built on tensors which are enriched arrays containing data and model parameters.\nYou can create tensors from\n\nlists\nnumpy arrays\nUsing built in initialization methods\n\n\n\nimport torch\nimport numpy as np\n\n# from list\na = [1, 2, 3]\nt_a = torch.tensor(a)\nprint(f\"list: {t_a}\")\n\n# from numpy\nb = torch.from_numpy(np.array([4, 5, 6], dtype=np.int32))\nt_b = torch.tensor(b)\nprint(f\"numpy: {t_b}\")\n\n# from ones\nc = torch.ones(2, 3)\nt_c = torch.tensor(c)\nprint(f\"ones: {t_c}\")\n\n# from ones\ntorch.manual_seed(1985)\nd = torch.rand(2, 3)\nt_d = torch.tensor(d)\nprint(f\"rand: {t_d}\")\n\nlist: tensor([1, 2, 3])\nnumpy: tensor([4, 5, 6], dtype=torch.int32)\nones: tensor([[1., 1., 1.],\n        [1., 1., 1.]])\nrand: tensor([[0.3651, 0.4031, 0.1296],\n        [0.0609, 0.5880, 0.4440]])\n\n\n/var/folders/s7/r5j2k3qx1fl3wlj7tn5574rm0000gn/T/ipykernel_68406/2435939936.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  t_b = torch.tensor(b)\n/var/folders/s7/r5j2k3qx1fl3wlj7tn5574rm0000gn/T/ipykernel_68406/2435939936.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  t_c = torch.tensor(c)\n/var/folders/s7/r5j2k3qx1fl3wlj7tn5574rm0000gn/T/ipykernel_68406/2435939936.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  t_d = torch.tensor(d)\n\n\nYou can access elements of the tensor using standard .loc() accessing.\n\ntorch.manual_seed(1985)\nx = torch.rand(2, 3)\n\nprint(f\"\"\"\n      x: {x}\n      shape: {x.shape}\n      first row: {x[0, :]}\n      first column: {x[:, 0]}\n      last element: {x[-1, -1]}\n    \"\"\")\n\n\n      x: tensor([[0.3651, 0.4031, 0.1296],\n        [0.0609, 0.5880, 0.4440]])\n      shape: torch.Size([2, 3])\n      first row: tensor([0.3651, 0.4031, 0.1296])\n      first column: tensor([0.3651, 0.0609])\n      last element: 0.4439687728881836\n    \n\n\nYou can manipulate data types using torch.to:\n\nt_a_new = t_a.to(torch.int64)\nprint(t_a_new.dtype)\n\ntorch.int64\n\n\nYou can reshape and transpose tensors using torch.reshape() and torch.transpose().\n\n# transpose\nt = torch.rand(3, 5)\nt_tr = t.transpose(0, 1)  # which two dimensions to transpose\nprint(t.shape, \"--&gt;\", t_tr.shape)\n\n# reshape\nt = torch.zeros(30)\nt_rs = t.reshape(5, 6)  # which two dimensions to transpose\nprint(t.shape, \"--&gt;\", t_rs.shape)\n\ntorch.Size([3, 5]) --&gt; torch.Size([5, 3])\ntorch.Size([30]) --&gt; torch.Size([5, 6])\n\n\ntorch.squeeze() drops all dimensions of a tensor that are redudant to reduce its rank.\n\nt = torch.ones(1, 1, 2)\nprint(f\"unsqueezed: {t}\")\nt_sqz = t.squeeze()  # removes redundant ranks\nprint(f\"squeezed: {t_sqz}\")\n\nunsqueezed: tensor([[[1., 1.]]])\nsqueezed: tensor([1., 1.])\n\n\nLinear algebraic operations are supported including * vector/matrix multiplication * statistical summaries (mean, standard deviation, etc) across axes\n\n# generate some data\ntorch.manual_seed(1985)\nx = 2.0 * torch.rand(5, 2) - 1.0\ny = torch.normal(mean=0.5, std=0.1, size=(5, 2))\n\n# element-wise multiplication\nmul = x * y\nprint(f\"mul: {mul.shape}\")\n\n# matrix multiplication\ninner = torch.mm(x.transpose(0, 1), y)\noutter = torch.mm(x, y.transpose(0, 1))\nprint(f\"inner: {inner.shape}, outer: {outter.shape}\")\n\n# row means and standard deviation\nrow_means = x.mean(dim=1)\nrow_stds = x.std(dim=1)\nprint(f\"row_means: {row_means}\\nrow_stds: {row_stds}\")\n\nmul: torch.Size([5, 2])\ninner: torch.Size([2, 2]), outer: torch.Size([5, 5])\nrow_means: tensor([-0.2318, -0.8095,  0.0320, -0.2714, -0.3531])\nrow_stds: tensor([0.0538, 0.0972, 0.2037, 0.8031, 0.5477])\n\n\nWe can also combine and manipulate tensors utilizing either: * Chunking - spliting the tensor into equal sizes (if possible) * Splitting - splitting the tensor into specified sizes (must be exact) * Concatenating - combining tensors along an existing dimension * Stacking - creates a new tensor by adding new dimensions to an existing tensor\n\n# generate the data\ntorch.manual_seed(1985)\nt = torch.rand(4, 2)\nprint(f\"t: {t}\")\n\n# chunking\nprint(\"--- CHUNKING --- \")\nt_splits = torch.chunk(t, 2, dim=0)\n[print(item.numpy()) for item in t_splits]\n\n# splitting\nprint(\"\\n--- SPLITTING --- \")\nt_splits = torch.split(t, split_size_or_sections=[2, 2], dim=0)\n[print(item.numpy()) for item in t_splits]\n\nt: tensor([[0.3651, 0.4031],\n        [0.1296, 0.0609],\n        [0.5880, 0.4440],\n        [0.6482, 0.0804]])\n--- CHUNKING --- \n[[0.36506873 0.40311843]\n [0.12958086 0.06087303]]\n[[0.5880055  0.44396877]\n [0.64821994 0.08037758]]\n\n--- SPLITTING --- \n[[0.36506873 0.40311843]\n [0.12958086 0.06087303]]\n[[0.5880055  0.44396877]\n [0.64821994 0.08037758]]\n\n\n[None, None]\n\n\n\n# concatenation\nx = torch.ones(3)\ny = torch.ones(3)\nz = torch.cat([x, y], axis=0)\nprint(f\"Concatenation: {z}\")\n\n# stacking\nz = torch.stack([x, y], axis=0)\nprint(f\"Stacking: {z}\")\n\nConcatenation: tensor([1., 1., 1., 1., 1., 1.])\nStacking: tensor([[1., 1., 1.],\n        [1., 1., 1.]])\n\n\n\n\nPreparing Training Dataset\nThere are a few popular ways to build datasets. We’ll focus on three primarily:\n\nDataset stores samples and labels.\nTensorDataSet is a Dataset build directly from torch tensors (typical for tabular ML)\nDataLoader loads provides an iterable on Dataset that allows you to load data in batches, shuffle samples, and load data in batches.\n\n\n\nComputational Graphs and Autograd\n\n\nNeural Network Modules\n\n\nPyTorch Training Loops\n\n\n\n\nn_epochs = 1 \nfor epoch in range(n_epochs):\n    for x_batch, y_batch in train_loader:\n        # 1. generate predictions \n        \n        # 2. calculate the loss \n        \n        # 3. back propogate loss \n        \n        # 4. update the weights\n        \n        # 5. reset the gradients to zero\n        \n        # 6. log the updated performance\n    \n    # 7. Accumulate the performance metrics for the epoch \n\n\n  Cell In[49], line 16\n    # 7. Accumulate the performance metrics for the epoch\n                                                          ^\nIndentationError: expected an indented block"
  },
  {
    "objectID": "notes/book-notes/isl-2023/chp2-lab/chp2.html",
    "href": "notes/book-notes/isl-2023/chp2-lab/chp2.html",
    "title": "Chapter 2 Lab",
    "section": "",
    "text": "Basic Commands\n\nprint(\"fit a model with\", 11, \"variables\")\n\nfit a model with 11 variables\n\n\n\nprint?\n\n\nDocstring:\n\nprint(value, ..., sep=' ', end='\\n', file=sys.stdout, flush=False)\n\n\n\nPrints the values to a stream, or to sys.stdout by default.\n\nOptional keyword arguments:\n\nfile:  a file-like object (stream); defaults to the current sys.stdout.\n\nsep:   string inserted between values, default a space.\n\nend:   string appended after the last value, default a newline.\n\nflush: whether to forcibly flush the stream.\n\nType:      builtin_function_or_method\n\n\n\n\n3 + 5\n\n8\n\n\n\n\"hello\" + \"world\"\n\n'helloworld'\n\n\n\n# sequenecs lists and tuples\nx = [3, 4, 5]\nx\n\n[3, 4, 5]\n\n\n\ny = [4, 9, 7]\nx + y\n\n[3, 4, 5, 4, 9, 7]\n\n\n\n## Adding sequence data gives back concatenation - true of strings too\n\n\n\nIntroduction to Numerical Python\n\n%pip install numpy\n\nCollecting numpy\n  Using cached numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl.metadata (60 kB)\nUsing cached numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl (5.3 MB)\nInstalling collected packages: numpy\nSuccessfully installed numpy-2.0.2\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport numpy as np\n\n\nx = np.array([3, 4, 5])\ny = np.array([4, 9, 7])\n\n\nx + y\n\narray([ 7, 13, 12])\n\n\n\n# also possible to create matrices via multi-dimensional arrays\n\nx = np.array([[1, 2], [3, 4]])\nx\n\narray([[1, 2],\n       [3, 4]])\n\n\n\nx.ndim, x.dtype\n\n(2, dtype('int64'))\n\n\n\n# implicit data type conversions\nx = np.array([[1, 2], [3.0, 4]])\nx.dtype\n\ndtype('float64')\n\n\n\nnp.array?\n\n\nDocstring:\n\narray(object, dtype=None, *, copy=True, order='K', subok=False, ndmin=0,\n\n      like=None)\n\n\n\nCreate an array.\n\n\n\nParameters\n\n----------\n\nobject : array_like\n\n    An array, any object exposing the array interface, an object whose\n\n    ``__array__`` method returns an array, or any (nested) sequence.\n\n    If object is a scalar, a 0-dimensional array containing object is\n\n    returned.\n\ndtype : data-type, optional\n\n    The desired data-type for the array. If not given, NumPy will try to use\n\n    a default ``dtype`` that can represent the values (by applying promotion\n\n    rules when necessary.)\n\ncopy : bool, optional\n\n    If ``True`` (default), then the array data is copied. If ``None``,\n\n    a copy will only be made if ``__array__`` returns a copy, if obj is\n\n    a nested sequence, or if a copy is needed to satisfy any of the other\n\n    requirements (``dtype``, ``order``, etc.). Note that any copy of\n\n    the data is shallow, i.e., for arrays with object dtype, the new\n\n    array will point to the same objects. See Examples for `ndarray.copy`.\n\n    For ``False`` it raises a ``ValueError`` if a copy cannot be avoided.\n\n    Default: ``True``.\n\norder : {'K', 'A', 'C', 'F'}, optional\n\n    Specify the memory layout of the array. If object is not an array, the\n\n    newly created array will be in C order (row major) unless 'F' is\n\n    specified, in which case it will be in Fortran order (column major).\n\n    If object is an array the following holds.\n\n\n\n    ===== ========= ===================================================\n\n    order  no copy                     copy=True\n\n    ===== ========= ===================================================\n\n    'K'   unchanged F & C order preserved, otherwise most similar order\n\n    'A'   unchanged F order if input is F and not C, otherwise C order\n\n    'C'   C order   C order\n\n    'F'   F order   F order\n\n    ===== ========= ===================================================\n\n\n\n    When ``copy=None`` and a copy is made for other reasons, the result is\n\n    the same as if ``copy=True``, with some exceptions for 'A', see the\n\n    Notes section. The default order is 'K'.\n\nsubok : bool, optional\n\n    If True, then sub-classes will be passed-through, otherwise\n\n    the returned array will be forced to be a base-class array (default).\n\nndmin : int, optional\n\n    Specifies the minimum number of dimensions that the resulting\n\n    array should have.  Ones will be prepended to the shape as\n\n    needed to meet this requirement.\n\nlike : array_like, optional\n\n    Reference object to allow the creation of arrays which are not\n\n    NumPy arrays. If an array-like passed in as ``like`` supports\n\n    the ``__array_function__`` protocol, the result will be defined\n\n    by it. In this case, it ensures the creation of an array object\n\n    compatible with that passed in via this argument.\n\n\n\n    .. versionadded:: 1.20.0\n\n\n\nReturns\n\n-------\n\nout : ndarray\n\n    An array object satisfying the specified requirements.\n\n\n\nSee Also\n\n--------\n\nempty_like : Return an empty array with shape and type of input.\n\nones_like : Return an array of ones with shape and type of input.\n\nzeros_like : Return an array of zeros with shape and type of input.\n\nfull_like : Return a new array with shape of input filled with value.\n\nempty : Return a new uninitialized array.\n\nones : Return a new array setting values to one.\n\nzeros : Return a new array setting values to zero.\n\nfull : Return a new array of given shape filled with value.\n\ncopy: Return an array copy of the given object.\n\n\n\n\n\nNotes\n\n-----\n\nWhen order is 'A' and ``object`` is an array in neither 'C' nor 'F' order,\n\nand a copy is forced by a change in dtype, then the order of the result is\n\nnot necessarily 'C' as expected. This is likely a bug.\n\n\n\nExamples\n\n--------\n\n&gt;&gt;&gt; np.array([1, 2, 3])\n\narray([1, 2, 3])\n\n\n\nUpcasting:\n\n\n\n&gt;&gt;&gt; np.array([1, 2, 3.0])\n\narray([ 1.,  2.,  3.])\n\n\n\nMore than one dimension:\n\n\n\n&gt;&gt;&gt; np.array([[1, 2], [3, 4]])\n\narray([[1, 2],\n\n       [3, 4]])\n\n\n\nMinimum dimensions 2:\n\n\n\n&gt;&gt;&gt; np.array([1, 2, 3], ndmin=2)\n\narray([[1, 2, 3]])\n\n\n\nType provided:\n\n\n\n&gt;&gt;&gt; np.array([1, 2, 3], dtype=complex)\n\narray([ 1.+0.j,  2.+0.j,  3.+0.j])\n\n\n\nData-type consisting of more than one element:\n\n\n\n&gt;&gt;&gt; x = np.array([(1,2),(3,4)],dtype=[('a','&lt;i4'),('b','&lt;i4')])\n\n&gt;&gt;&gt; x['a']\n\narray([1, 3])\n\n\n\nCreating an array from sub-classes:\n\n\n\n&gt;&gt;&gt; np.array(np.asmatrix('1 2; 3 4'))\n\narray([[1, 2],\n\n       [3, 4]])\n\n\n\n&gt;&gt;&gt; np.array(np.asmatrix('1 2; 3 4'), subok=True)\n\nmatrix([[1, 2],\n\n        [3, 4]])\n\nType:      builtin_function_or_method\n\n\n\n\nnp.array([[1, 2], [3, 4]], dtype=float).dtype\n\ndtype('float64')\n\n\n\nx.shape\n\n(2, 2)\n\n\n\nx.sum()  # implicitly passes x as the first argument to the method e.g. sum(self, ...)\n\nnp.float64(10.0)\n\n\n\nnp.sum(x)\n\nnp.float64(10.0)\n\n\n\n# we can also reshape on the go too\nx = np.array([1, 2, 3, 4, 5, 6])\nprint(x)\nx_reshape = x.reshape((2, 3))\nprint(x_reshape)\n\n[1 2 3 4 5 6]\n[[1 2 3]\n [4 5 6]]\n\n\nNotice that numpy cut the dataframe as a seqeunce of rows - not a sequence of columns first. This is called row major ordering.\n\nx_reshape[0, 0]\n\nnp.int64(1)\n\n\n\nx_reshape[1, 2]\n\nnp.int64(6)\n\n\n\nx[3]\n\nnp.int64(4)\n\n\n\nprint(x_reshape)\nx_reshape[0, 0] = 5\nprint(x_reshape)\n\n[[1 2 3]\n [4 5 6]]\n[[5 2 3]\n [4 5 6]]\n\n\n\nprint(x)\n\n[5 2 3 4 5 6]\n\n\nNotice that since x and x  reshape_ point to the same place in memory, modifying that place modifies both.\nRecall that tuples are not mutable so we have\n\ny = (3, 4, 5)\ny[0] = 2\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[37], line 2\n      1 y = (3, 4, 5)\n----&gt; 2 y[0] = 2\n\nTypeError: 'tuple' object does not support item assignment\n\n\n\n\nx_reshape.shape, x_reshape.ndim, x_reshape.T\n\n((2, 3),\n 2,\n array([[5, 4],\n        [2, 5],\n        [3, 6]]))\n\n\n\nnp.sqrt(x)\n\narray([2.23606798, 1.41421356, 1.73205081, 2.        , 2.23606798,\n       2.44948974])\n\n\n\nx**2\n\narray([25,  4,  9, 16, 25, 36])\n\n\n\nx**0.5\n\narray([2.23606798, 1.41421356, 1.73205081, 2.        , 2.23606798,\n       2.44948974])\n\n\n\n# We can also randomly generate data\n\n# normal random data\nnp.random.normal?\n\n\nSignature: np.random.normal(loc=0.0, scale=1.0, size=None)\n\nDocstring:\n\nnormal(loc=0.0, scale=1.0, size=None)\n\n\n\nDraw random samples from a normal (Gaussian) distribution.\n\n\n\nThe probability density function of the normal distribution, first\n\nderived by De Moivre and 200 years later by both Gauss and Laplace\n\nindependently [2]_, is often called the bell curve because of\n\nits characteristic shape (see the example below).\n\n\n\nThe normal distributions occurs often in nature.  For example, it\n\ndescribes the commonly occurring distribution of samples influenced\n\nby a large number of tiny, random disturbances, each with its own\n\nunique distribution [2]_.\n\n\n\n.. note::\n\n    New code should use the `~numpy.random.Generator.normal`\n\n    method of a `~numpy.random.Generator` instance instead;\n\n    please see the :ref:`random-quick-start`.\n\n\n\nParameters\n\n----------\n\nloc : float or array_like of floats\n\n    Mean (\"centre\") of the distribution.\n\nscale : float or array_like of floats\n\n    Standard deviation (spread or \"width\") of the distribution. Must be\n\n    non-negative.\n\nsize : int or tuple of ints, optional\n\n    Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n\n    ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n\n    a single value is returned if ``loc`` and ``scale`` are both scalars.\n\n    Otherwise, ``np.broadcast(loc, scale).size`` samples are drawn.\n\n\n\nReturns\n\n-------\n\nout : ndarray or scalar\n\n    Drawn samples from the parameterized normal distribution.\n\n\n\nSee Also\n\n--------\n\nscipy.stats.norm : probability density function, distribution or\n\n    cumulative density function, etc.\n\nrandom.Generator.normal: which should be used for new code.\n\n\n\nNotes\n\n-----\n\nThe probability density for the Gaussian distribution is\n\n\n\n.. math:: p(x) = \\frac{1}{\\sqrt{ 2 \\pi \\sigma^2 }}\n\n                 e^{ - \\frac{ (x - \\mu)^2 } {2 \\sigma^2} },\n\n\n\nwhere :math:`\\mu` is the mean and :math:`\\sigma` the standard\n\ndeviation. The square of the standard deviation, :math:`\\sigma^2`,\n\nis called the variance.\n\n\n\nThe function has its peak at the mean, and its \"spread\" increases with\n\nthe standard deviation (the function reaches 0.607 times its maximum at\n\n:math:`x + \\sigma` and :math:`x - \\sigma` [2]_).  This implies that\n\nnormal is more likely to return samples lying close to the mean, rather\n\nthan those far away.\n\n\n\nReferences\n\n----------\n\n.. [1] Wikipedia, \"Normal distribution\",\n\n       https://en.wikipedia.org/wiki/Normal_distribution\n\n.. [2] P. R. Peebles Jr., \"Central Limit Theorem\" in \"Probability,\n\n       Random Variables and Random Signal Principles\", 4th ed., 2001,\n\n       pp. 51, 51, 125.\n\n\n\nExamples\n\n--------\n\nDraw samples from the distribution:\n\n\n\n&gt;&gt;&gt; mu, sigma = 0, 0.1 # mean and standard deviation\n\n&gt;&gt;&gt; s = np.random.normal(mu, sigma, 1000)\n\n\n\nVerify the mean and the variance:\n\n\n\n&gt;&gt;&gt; abs(mu - np.mean(s))\n\n0.0  # may vary\n\n\n\n&gt;&gt;&gt; abs(sigma - np.std(s, ddof=1))\n\n0.1  # may vary\n\n\n\nDisplay the histogram of the samples, along with\n\nthe probability density function:\n\n\n\n&gt;&gt;&gt; import matplotlib.pyplot as plt\n\n&gt;&gt;&gt; count, bins, ignored = plt.hist(s, 30, density=True)\n\n&gt;&gt;&gt; plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *\n\n...                np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n\n...          linewidth=2, color='r')\n\n&gt;&gt;&gt; plt.show()\n\n\n\nTwo-by-four array of samples from the normal distribution with\n\nmean 3 and standard deviation 2.5:\n\n\n\n&gt;&gt;&gt; np.random.normal(3, 2.5, size=(2, 4))\n\narray([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],   # random\n\n       [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]])  # random\n\nType:      method\n\n\n\n\nx = np.random.normal(size=50)\nx\n\narray([-0.93230525,  1.15415226,  2.345425  ,  0.34701473, -0.18367794,\n        0.84070946,  0.52871946,  0.3124265 ,  0.94375236, -0.79683836,\n       -0.58169344, -0.0931726 ,  1.23470654,  0.49378801,  0.86116695,\n       -2.13489222, -2.27776071, -0.78684985,  0.7464952 ,  0.3479821 ,\n       -0.03938126, -2.30878037,  0.25280371, -0.5023934 , -0.65121185,\n        0.41767052,  0.14501507,  1.01085326, -0.39508961, -0.37561308,\n        1.90311237, -1.10075158, -0.97612821,  0.13494495,  0.50784609,\n       -0.34257389,  0.50480447,  0.88943124, -1.92557035, -0.17121948,\n       -1.66822946, -2.22893469,  1.05790807, -0.29303062, -1.95205855,\n        1.10471947, -0.78598444, -1.18678982, -0.79555294, -0.07121685])\n\n\n\ny = x + np.random.normal(loc=50, scale=1, size=50)\n\n\n# correlation coefficient\nnp.corrcoef(x, y)\n\narray([[1.        , 0.70088018],\n       [0.70088018, 1.        ]])\n\n\n\n# we have different seeds so\nprint(np.random.normal(scale=5, size=2))\nprint(np.random.normal(scale=5, size=2))\n\n[-1.73852581  5.50593231]\n[-0.9240053 -4.5153519]\n\n\n\n# we can set a random seed by\nrng = np.random.default_rng(1303)\nprint(rng.normal(scale=5, size=2))\nrng2 = np.random.default_rng(1303)\nprint(rng2.normal(scale=5, size=2))\n\n[ 4.09482632 -1.07485605]\n[ 4.09482632 -1.07485605]\n\n\n\n# we can use this to show how to get empirical moments\n\nrng = np.random.default_rng(1234)\ny = rng.standard_normal(10)\nnp.mean(y), y.mean()\n\n(np.float64(0.12748754499933185), np.float64(0.12748754499933185))\n\n\n\n# variance - notice these are not biased corrected\nnp.var(y), y.var(), np.mean((y - y.mean()) ** 2)\n\n(np.float64(1.8193289053764339),\n np.float64(1.8193289053764339),\n np.float64(1.8193289053764339))\n\n\n\n# we can change this by setting the ddof argument\nnp.var(y, ddof=1), y.var(ddof=1)\n\n(np.float64(2.021476561529371), np.float64(2.021476561529371))\n\n\n\nnp.sqrt(np.var(y)), y.std()\n\n(np.float64(1.3488250091751834), np.float64(1.3488250091751834))\n\n\n\n# We can also apply these across the rows and columns of both of these matrices"
  },
  {
    "objectID": "notes/book-notes/rashka-2022/chp14.html",
    "href": "notes/book-notes/rashka-2022/chp14.html",
    "title": "Chapter 14: Classifying Images with Deep CNNs",
    "section": "",
    "text": "Chapter layout:\n\nUnderstanding Convolutions\nImplementing a CNN\nImplementing a Deep CNN with PyTorch\nSmile Classification using a CNN\n\n\nUnderstanding Convolutions\n\nCNNs are a family of models that were inspired from the visual cortext of the human brain.\n\nNeurons responds differently to light: the primary layer detects edges, higher order layers detect shapes and patterns\n\nOrginalally developed by Yann LeCun and colleagues in the 1990s\nCNNs are usually refered to as feature extraction layers\n\nCNNs are usually thought of as feature extraction layers that are able to extract low-level features in the early layers which are utilized later in the network to detect patterns between these features and the target variable of interest.\nCNNs construct a feature hierachy by combining low-level features to form high-level features.\nCNN computes feature maps from an input image to create a feature. They look over local receptive fields = local patch of pixels to construct and pool features in small areas of the image.\nThis method relies on * sparse connectivity = an element of a feature map is only connected to its nearest neighbor * parameter sharing = by learning a common set of parameters in a patch, we can utilize it in different parts of the image\nTypically a CNN is constructed of\n\nSeveral convolutional layers\nSubsampling / Pooling layers\n\nThese don’t have any weights or biases, just a useful aggregator\n\nFully connected layers\n\nA discrete convolution in 1D\nA convolution for two discrete vectors is \\(x\\) and \\(y\\) is given by\n\\[ z = x * y \\rightarrow z_i = \\sum_{k=\\infty}^{\\infty}x[i-k]y[k]\\]\nwhere it is assumed \\(x[i] = y[j] = 0\\) for all non-index elements of \\(x\\) and \\(y\\).\nThe process of filling these zeros is called zero padding. In addition to utilize the dot prodct it is typically to ‘flip’ the second vector and then dot it with the padded vector.\nThis gives the effect of “sliding” the smaller of the two vectors across it, and taking a localized weighted sum (dot product) to store in the convolution.\nThis convolution has two hyperparamter\n\nPadding = how much additional zeros do we add to the vector to get\nStride = how far down the vector do we shift to take the next product\n\nAside: This is like if we had a vector length 10 and we had a convolution of length 10, we’d only get a single number with no padding. By adding a bunch of zeros to the end of the vector, we can take local averages of the pixels toward the end of the arrays by themselves (e.g. [0, 1, 2] and [7, 8, 9])\nWe can use padding and stride lengths to determine the length of the output of the convolution. The three most popular modes of padding are\n\nFull = \\(p = m-1\\) this is super largr and starts so the first element \\(z[0] = x[0]\\). For this reason, it’s rarely used.\nSame = \\(p\\) is selected so that the size of the output matches the input.\nValid = \\(p=0\\) ensures that there is no padding at all.\n\nSame padding is the most used in CNNs. It’s typically to do a same padding CNNs layer followed by pooling or further convultional layers with higher stride lengths to decrease size for example: https://arxiv.org/abs/1412.6806\nTo determine the size of the convolutional output layer, we need to understand how many times we shift the filter along the input vector. The fomula is given by\n\\[ o = \\lfloor\\frac{n + 2p -m}{s} \\rfloor + 1 \\]\nwhere * n = input size * p = padding size * m = filter size * s = stride length\nA naive implementation is given below:\n\nimport numpy as np\n\n\ndef conv1d(x, y, p=0, s=1):\n    y_rot = np.array(y[::-1])\n    x_pad = np.array(x)\n    if p &gt; 0:\n        zero_pad = np.zeros(shape=p)\n        x_pad = np.concatenate([zero_pad, x_pad, zero_pad])\n    res = []\n    for i in range(0, int((len(x_pad) - len(y_rot)) + 1), s):\n        # range(0, int((len(x_pad) - len(w_rot))) + 1, s)\n        res.append(np.sum(x_pad[i : i + y_rot.shape[0]] * y_rot))\n\n    return np.array(res)\n\n\nx = [1, 3, 2, 4, 5, 6, 1, 3]\ny = [1, 0, 3, 1, 2]\n\nprint(\"Conv1D Implementation:\", conv1d(x, y, p=2, s=1))\n\nConv1D Implementation: [ 5. 14. 16. 26. 24. 34. 19. 22.]\n\n\n\nprint(\"Numpy results:\", np.convolve(x, y, mode=\"same\"))\n\nNumpy results: [ 5 14 16 26 24 34 19 22]\n\n\n\n\nPerforming 2D Convolutions\nFor a two dimensional convoultion we have\n\\[Z = X * Y \\rightarrow Z[i,j] = \\sum_{k_1=-\\infty}^{\\infty}\\sum_{k_2=-\\infty}^{\\infty}X[i-k_1, j-k_2]Y[k_1, k_2] \\]\nThis operation has the effect of passing a filter matrix \\(Y\\) over the matrix \\(X\\) and creating small localized weighted means. This obviously has clear applications in image feature extraction where we want to locally pool pixels in an image.\n\nimport numpy as np\nimport scipy.signal\n\n\ndef conv2d(X, Y, p=(0, 0), s=(1, 1)):\n    Y_rot = np.array(Y)[::-1, ::-1]\n    X_orig = np.array(X)\n\n    n1 = X_orig.shape[0] + 2 * p[0]\n    n2 = X_orig.shape[1] + 2 * p[1]\n\n    X_padded = np.zeros(shape=(n1, n2))\n    X_padded[p[0] : p[0] + X_orig.shape[0], p[1] : p[1] + X_orig.shape[1]] = X_orig\n\n    res = []\n    for i in range(0, int((X_padded.shape[0] - Y_rot.shape[0]) / s[0]) + 1, s[0]):\n        res.append([])\n        for j in range(0, int((X_padded.shape[1] - Y_rot.shape[1]) / s[1]) + 1, s[1]):\n            X_sub = X_padded[i : i + Y_rot.shape[0], j : j + Y_rot.shape[1]]\n            res[-1].append(np.sum(X_sub * Y_rot))\n\n    return np.array(res)\n\n\nX = [[1, 3, 2, 4], [5, 6, 1, 3], [1, 2, 0, 2], [3, 4, 3, 2]]\nY = [[1, 0, 3], [1, 2, 1], [0, 1, 1]]\n\n\nx = conv2d(X, Y, p=(1, 1), s=(1, 1))\nprint(\"Conv2d Implentation:\\n\", x)\n\nConv2d Implentation:\n [[11. 25. 32. 13.]\n [19. 25. 24. 13.]\n [13. 28. 25. 17.]\n [11. 17. 14.  9.]]\n\n\n\nprint(\"SciPy Implementation:\\n\", scipy.signal.convolve2d(X, Y, mode=\"same\"))\n\nSciPy Implementation:\n [[11 25 32 13]\n [19 25 24 13]\n [13 28 25 17]\n [11 17 14  9]]\n\n\nA few notes on scaling\n\nYou can do these way faster by using fourier transform tricks\nIt typical to have a kernel that is much smaller than the input image\n\nTypical to have (1, 1), (3, 3) and (5,5) kernels\n\n\n\n\nSubsampling Layers\nThere are two types of pooling layers in CNNs which decrease the size of the feature set and reduces the dependence on one pixel in the image encouraging generalizability.\n\nmax pooling = take the max in pixel neighborhood\nmean pooling = take the mean in pixel neighborhood\n\nAnd the neighborhod size (or pooling size) determines the size of the neighborhood.\nMax pooling is great for local heterogenity and robust to noise in the input data. Mean pooling\nThese can be used to reduce feature size OR another convolution layer with higher stride lengths.\nTo understand the differences between these two aproaches see here: https://arxiv.org/abs/1412.6806\n\n\nImplementing a CNN\nThey key difference between tabular ANNs and CNNs is how we process the inputs:\n\nANN: \\(z_1 = Wx + b\\) where \\(x\\) is a vectorized input of pixels\nCNN: \\(z_1 = W*X + b\\) where \\(X\\) is a matrix of pixels passed via a convolution\n\nSince pictures could be represented in multiple colors we need to understand how to process color channels.\nEach picture will be represented by a \\(n_1 \\times n_2 \\times c\\) tensor where \\(c\\) is the number of color channels.\n\n# reading in images\nimport torch\nfrom torchvision.io import read_image\n\nimg = read_image(\"./figures/other/cat.png\")\n\nprint(\"Image shape:\", img.shape)\nprint(\"Number of channels:\", img.shape[0])\nprint(\"Image data type:\", img.dtype)\n\nImage shape: torch.Size([4, 360, 360])\nNumber of channels: 4\nImage data type: torch.uint8\n\n\n\nprint(img[:, 100:102, 100:102])\n\ntensor([[[140, 132],\n         [129, 135]],\n\n        [[140, 132],\n         [129, 135]],\n\n        [[140, 132],\n         [129, 135]],\n\n        [[  0,   0],\n         [  0,   0]]], dtype=torch.uint8)\n\n\nGiven this how can we incorperate each channel into our convolution? We do it for each channel then add them together.\nSuppose each channel has it owns kernel matrix \\(W[::c]\\) then the pre-activation inputs are given by\n\\[Z^{(conv)} = \\sum_{c=1}^CW[:,:,c] * X[:, :, c] \\] \\[Z = Z^{(conv)} + b\\] \\[A = \\sigma(Z)\\]\nWhere this last matrix \\(A\\) is called our feature map.\nIt is typical for a CNN layer to have more than one feature map which is specificed by passing different kernels over each channel. That is:\n\\[Z^{(conv)}[:,:,k] = \\sum_{c=1}^CW[:,:,c, k] * X[:, :, c]\\] \\[Z[:,:,k] = Z^{(conv)}[:,:,k] + b[k]\\] \\[A[:,:,k] = \\sigma(Z[:,:,k)\\]\nwhich supplies us with \\(K\\) different feature maps which can be used in subsequent layers for learning.\nSo the steps are as follows:\n\nFor each kernel \\(K\\), convolve over each channel \\(C\\) and add them up.\nDo this for each kernel which provides \\(K\\) new elements to work with.\nPerform max pooling with also results in \\(K\\) elements but of possible smaller dimesion\n\nAside: This was not super well explained. The point is that you can create individual feature maps by passing different kerels over each channel. Aggregating those feature maps serves as useful inputs for down the network. Morever, the network can learn what these kernels should be to maximize impact of these feature maps.\nRegularization\nThese models truly have an insane number of weights so learning how to perform regularization seems really important.\nWe’ll disuss \\(\\ell_2\\) regularization by regularizating the parameters in each layer and dropout which randomly drops nodes from the network during training to ensure no one section of the network becomes too important and removes ReLu dead neurons.\n\n# ell_2 regularization\n\nimport torch.nn as nn\n\nloss_func = nn.BCELoss()\nloss = loss_func(torch.tensor([0.9]), torch.tensor([1.0]))\nl2_lambda = 0.001\n\nconv_layer = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=5)\nl2_penalty = l2_lambda * sum([(p**2).sum() for p in conv_layer.parameters()])\nloss_with_penalty = loss + l2_penalty\n\nlinear_layer = nn.Linear(10, 16)\nl2_penalty = l2_lambda * sum([(p**2).sum() for p in linear_layer.parameters()])\nloss_with_penalty = loss + l2_penalty\n\nWhile we can use this droput remains the most important regularization method.\nDuring training, we will randomly drop neurons with a certain probability \\(p\\) (commonly set to \\(p=0.5\\)). This forces the network to learn redudant information in the training data increasing the model’s robustness.\nImplicitly this technique is performing ensemble learning as it learns different parts of feature-label relationship during each epoch.\nAside: There is a very out of place discussion on the difference between categorial and binary classification and the differ ways to implement in in PyTorch which we’ll now code up.\n\n# Binary Cross Entropy\nlogits = torch.tensor([0.8])\nprobs = torch.sigmoid(logits)\ntarget = torch.tensor([1.0])\nbce_loss_fn = nn.BCELoss()\nbce_logits_loss_fn = nn.BCEWithLogitsLoss()\nprint(f\"BCE (with Probs): {bce_loss_fn(probs, target):.4f}\")\nprint(f\"BCE (with Logits): {bce_logits_loss_fn(logits, target):.4f}\")\n\nBCE (with Probs): 0.3711\nBCE (with Logits): 0.3711\n\n\n\n# Categorical Cross Entropy\nlogits = torch.tensor([[1.5, 0.8, 2.1]])\nprobs = torch.softmax(logits, dim=1)\ntarget = torch.tensor([2])\ncce_loss_fn = nn.NLLLoss()\ncce_logits_loss_fn = nn.CrossEntropyLoss()\nprint(f\"CCE (with Probs): {cce_loss_fn(torch.log(probs), target):.4f}\")\nprint(f\"CCE (with Logits): {cce_logits_loss_fn(logits, target):.4f}\")\n\nCCE (with Probs): 0.5996\nCCE (with Logits): 0.5996\n\n\n\n\nImplementing a CNN with PyTorch\nWe will work with greyscale images and process batchsize images at a time. Therefore our input tensor will be \\(batchsize 28 \\times 28 \\times 1\\) in size.\nFrom here we can summarize the CNN architecture as follows:\n\nWe will put the images through two CNN layers with a kernel size of \\(5\\times 5\\).\nWe will extract 32 feature maps from the first layer and 64 from teh second\nWe proces each CNN layer with a max pooling layer of size \\(2\\times 2\\).\nWe then flatten these and pass it through two fully connected layers to a multi-output head.\n\nThe dimensions can be summarized as follows:\n\nInput: \\([bs \\times 28\\times 28 \\times 1]\\)\nConv1: \\([bs \\times 28 \\times 28 \\times 32]\\)\nPooling1: \\([bs \\times 14 \\times 14 \\times 32]\\)\nConv2: \\([bs \\times 14 \\times 14 \\times 64]\\)\nPooling2: \\([bs \\times 7 \\times 7 \\times 64]\\)\nFC1: \\([bs \\times 1024]\\)\nFC2 and softmax: \\([bs \\times 10]\\)\n\n\n# load and preprocess MNIST\nimport torchvision\nfrom torchvision import transforms\nfrom torch.utils.data import Subset\n\nimage_path = \"./figures/\"\n\ntransform = transforms.Compose([transforms.ToTensor()])\nmnist_dataset = torchvision.datasets.MNIST(\n    root=image_path, train=True, transform=transform, download=False\n)\n\n\nmnist_valid_dataset = Subset(mnist_dataset, torch.arange(10_000))\nmnist_train_dataset = Subset(mnist_dataset, torch.arange(10_000, len(mnist_dataset)))\nmnist_test_dataset = torchvision.datasets.MNIST(\n    root=image_path, train=False, transform=transform, download=False\n)\n\n\n# create data loader to batch in 64 images at a time\n\nfrom torch.utils.data import DataLoader\n\nbatch_size = 64\ntorch.manual_seed(1)\ntrain_d1 = DataLoader(mnist_train_dataset, batch_size, shuffle=True)\n\nvalid_d1 = DataLoader(mnist_valid_dataset, batch_size, shuffle=False)\n\nFor implementation we will use the nn.Sequential module to stack different layers. Each layer will come as a subclass from the base nn.Module class\n\nnn.Conv2d = convolutional layer\nnn.maxPool2d = max pooling layer\nnn.AvgPool2d = average pooling layer\nnn.Dropout = dropout layer\n\n\nmodel = nn.Sequential()\n\n# add first convolutional layer\nmodel.add_module(\n    \"conv1\",\n    nn.Conv2d(\n        in_channels=1,  # number of channels incoming\n        out_channels=32,  # number of feature maps to extract\n        kernel_size=5,  # size of window\n        padding=2,  # padding of image\n    ),\n)\nmodel.add_module(\"relu1\", nn.ReLU())\nmodel.add_module(\"pool1\", nn.MaxPool2d(kernel_size=2))\n\n# add second convolutional layer\nmodel.add_module(\n    \"conv2\",\n    nn.Conv2d(\n        in_channels=32,  # number of channels incoming\n        out_channels=64,  # number of feature maps to extract\n        kernel_size=5,  # size of window\n        padding=2,  # padding of image\n    ),\n)\nmodel.add_module(\"relu2\", nn.ReLU())\nmodel.add_module(\"pool2\", nn.MaxPool2d(kernel_size=2))\n\n\n# We can compute the output size of the network at this stage by computing:\n\nx = torch.ones((4, 1, 28, 28))\nmodel(x).shape\n\n# which gives 4 images, 64 feature maps, of size 7x7\n\ntorch.Size([4, 64, 7, 7])\n\n\n\n# now flatten and pass through fully connected layers\n\nmodel.add_module(\"flatten\", nn.Flatten())\nmodel(x).shape\n\ntorch.Size([4, 3136])\n\n\n\nmodel.add_module(\"fc1\", nn.Linear(3136, 1024))\nmodel.add_module(\"relu3\", nn.ReLU())\nmodel.add_module(\"dropout\", nn.Dropout(p=0.5))\nmodel.add_module(\"fc2\", nn.Linear(1024, 10))\n\n\n# create optimizer and loss\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n\n# training loop\ndef train(model, num_epochs, train_d1, valid_d1):\n    loss_hist_train = [0] * num_epochs\n    accuracy_hist_train = [0] * num_epochs\n    loss_hist_valid = [0] * num_epochs\n    accuracy_hist_valid = [0] * num_epochs\n    for epoch in range(num_epochs):\n        model.train()  # set to train mode because of dropout!\n        for x_batch, y_batch in train_d1:\n            # get predictions\n            pred = model(x_batch)\n\n            # compute loss and back propogate\n            loss = loss_fn(pred, y_batch)\n            loss.backward()\n\n            # optimize\n            optimizer.step()\n            optimizer.zero_grad()\n\n            # log\n            loss_hist_train[epoch] += loss.item() * y_batch.size(0)\n            is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n            accuracy_hist_train[epoch] += is_correct.sum()\n\n        loss_hist_train[epoch] /= len(train_d1.dataset)\n        accuracy_hist_train[epoch] /= len(train_d1.dataset)\n\n        model.eval()\n        with torch.no_grad():\n            for x_batch, y_batch in valid_d1:\n                pred = model(x_batch)\n                loss = loss_fn(pred, y_batch)\n                loss_hist_valid[epoch] += loss.item() * y_batch.size(0)\n                is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n                accuracy_hist_valid[epoch] += is_correct.sum()\n\n        loss_hist_valid[epoch] /= len(valid_d1.dataset)\n        accuracy_hist_valid[epoch] /= len(valid_d1.dataset)\n\n        print(f\"\"\"\n              Epoch {epoch + 1} \n              Train accuracy: {accuracy_hist_train[epoch]:.4f} \n              Validation accuracy {accuracy_hist_valid[epoch]:.4f} \n              \"\"\")\n\n\ntorch.manual_seed(1)\nnum_epochs = 20\nhist = train(model, num_epochs, train_d1, valid_d1)\n\n\nimport matplotlib.pyplot as plt\nx_arr = np.arange(len(hist[0])) + 1\nfig = plt.figure(figsize=(12, 4))\nax = fig.add_subplot(1, 2, 1)\nax.plot(x_arr, hist[0],  '-o', label='Train loss')\nax.plot(x_arr, hist[1],  '--&lt;', label='Validation loss')\nax.legend(fontsize=15)\nax = fig.add_subplot(1, 2, 2)\nax.plot(x_arr, hist[2],  '-o', label='Train acc.') &gt;&gt;&gt; ax.plot(x_arr, hist[3],  '--&lt;',\n                                                               label='Validation acc.')\nax.legend(fontsize=15)\nax.set_xlabel('Epoch', size=15)\nax.set_ylabel('Accuracy', size=15)\nplt.show()"
  }
]